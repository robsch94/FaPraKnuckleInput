{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "#from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': \"758990540:AAFrdfPpNGctKEvoMvMm3vFpj_VwY_BeOA4\",   # paste your bot token\n",
    "    'telegram_id': 158106307,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14]\n",
    "test_ids = [4,5,6,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfAll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b46b0c972366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfAll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserID\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dfAll' is not defined"
     ]
    }
   ],
   "source": [
    "dfAll.userID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "#Create InputMethod Column and fill it with Knuckel / Finger\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 27, 15, 120)       1200      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 27, 15, 120)       129720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 7, 120)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13, 7, 120)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 7, 50)         54050     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 7, 50)         22550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6, 3, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               360400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 608,222\n",
      "Trainable params: 608,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 47696 samples, validate on 30086 samples\n",
      "Epoch 1/500\n",
      "47696/47696 [==============================] - 23s 477us/step - loss: 0.3971 - acc: 0.8205 - val_loss: 0.2625 - val_acc: 0.8892\n",
      "Epoch 2/500\n",
      "47696/47696 [==============================] - 21s 451us/step - loss: 0.2409 - acc: 0.8967 - val_loss: 0.2365 - val_acc: 0.9068\n",
      "Epoch 3/500\n",
      "47696/47696 [==============================] - 22s 457us/step - loss: 0.2078 - acc: 0.9119 - val_loss: 0.2133 - val_acc: 0.9216\n",
      "Epoch 4/500\n",
      "47696/47696 [==============================] - 22s 452us/step - loss: 0.1873 - acc: 0.9221 - val_loss: 0.1927 - val_acc: 0.9281\n",
      "Epoch 5/500\n",
      "47696/47696 [==============================] - 22s 461us/step - loss: 0.1758 - acc: 0.9272 - val_loss: 0.1933 - val_acc: 0.9274\n",
      "Epoch 6/500\n",
      "47696/47696 [==============================] - 22s 454us/step - loss: 0.1673 - acc: 0.9324 - val_loss: 0.2464 - val_acc: 0.9092\n",
      "Epoch 7/500\n",
      "47696/47696 [==============================] - 22s 453us/step - loss: 0.1570 - acc: 0.9370 - val_loss: 0.2564 - val_acc: 0.9132\n",
      "Epoch 8/500\n",
      "47696/47696 [==============================] - 21s 450us/step - loss: 0.1515 - acc: 0.9392 - val_loss: 0.2178 - val_acc: 0.9244\n",
      "Epoch 9/500\n",
      "47696/47696 [==============================] - 22s 452us/step - loss: 0.1440 - acc: 0.9424 - val_loss: 0.2841 - val_acc: 0.8986\n",
      "Epoch 10/500\n",
      "47696/47696 [==============================] - 21s 447us/step - loss: 0.1422 - acc: 0.9438 - val_loss: 0.2183 - val_acc: 0.9213\n",
      "Epoch 11/500\n",
      "47696/47696 [==============================] - 22s 454us/step - loss: 0.1320 - acc: 0.9470 - val_loss: 0.1807 - val_acc: 0.9348\n",
      "Epoch 12/500\n",
      "47696/47696 [==============================] - 21s 446us/step - loss: 0.1299 - acc: 0.9492 - val_loss: 0.2498 - val_acc: 0.9157\n",
      "Epoch 13/500\n",
      "47696/47696 [==============================] - 21s 450us/step - loss: 0.1248 - acc: 0.9513 - val_loss: 0.2198 - val_acc: 0.9356\n",
      "Epoch 14/500\n",
      "47696/47696 [==============================] - 21s 448us/step - loss: 0.1215 - acc: 0.9512 - val_loss: 0.2689 - val_acc: 0.9205\n",
      "Epoch 15/500\n",
      "47696/47696 [==============================] - 22s 453us/step - loss: 0.1152 - acc: 0.9549 - val_loss: 0.2186 - val_acc: 0.9304\n",
      "Epoch 16/500\n",
      "47696/47696 [==============================] - 21s 450us/step - loss: 0.1142 - acc: 0.9558 - val_loss: 0.2002 - val_acc: 0.9329\n",
      "Epoch 17/500\n",
      "47696/47696 [==============================] - 21s 450us/step - loss: 0.1074 - acc: 0.9591 - val_loss: 0.2014 - val_acc: 0.9395\n",
      "Epoch 18/500\n",
      "47696/47696 [==============================] - 22s 452us/step - loss: 0.1090 - acc: 0.9576 - val_loss: 0.2739 - val_acc: 0.9281\n",
      "Epoch 19/500\n",
      "47696/47696 [==============================] - 22s 454us/step - loss: 0.1053 - acc: 0.9582 - val_loss: 0.1944 - val_acc: 0.9326\n",
      "Epoch 20/500\n",
      "47696/47696 [==============================] - 22s 470us/step - loss: 0.1004 - acc: 0.9602 - val_loss: 0.2262 - val_acc: 0.9341\n",
      "Epoch 21/500\n",
      "47696/47696 [==============================] - 24s 502us/step - loss: 0.0976 - acc: 0.9619 - val_loss: 0.2578 - val_acc: 0.9259\n",
      "Epoch 22/500\n",
      "47696/47696 [==============================] - 24s 507us/step - loss: 0.0936 - acc: 0.9634 - val_loss: 0.2627 - val_acc: 0.9278\n",
      "Epoch 23/500\n",
      "47696/47696 [==============================] - 24s 507us/step - loss: 0.0915 - acc: 0.9645 - val_loss: 0.2732 - val_acc: 0.9207\n",
      "Epoch 24/500\n",
      "47696/47696 [==============================] - 24s 508us/step - loss: 0.0886 - acc: 0.9652 - val_loss: 0.2549 - val_acc: 0.9293\n",
      "Epoch 25/500\n",
      "47696/47696 [==============================] - 24s 502us/step - loss: 0.0875 - acc: 0.9658 - val_loss: 0.2697 - val_acc: 0.9291\n",
      "Epoch 26/500\n",
      "47696/47696 [==============================] - 24s 505us/step - loss: 0.0849 - acc: 0.9665 - val_loss: 0.3043 - val_acc: 0.9257\n",
      "Epoch 27/500\n",
      "47696/47696 [==============================] - 24s 499us/step - loss: 0.0801 - acc: 0.9683 - val_loss: 0.2690 - val_acc: 0.9279\n",
      "Epoch 28/500\n",
      "47696/47696 [==============================] - 24s 507us/step - loss: 0.0675 - acc: 0.9726 - val_loss: 0.2473 - val_acc: 0.9344\n",
      "Epoch 34/500\n",
      "47696/47696 [==============================] - 24s 509us/step - loss: 0.0689 - acc: 0.9731 - val_loss: 0.2916 - val_acc: 0.9328\n",
      "Epoch 35/500\n",
      "47696/47696 [==============================] - 24s 508us/step - loss: 0.0655 - acc: 0.9746 - val_loss: 0.2618 - val_acc: 0.9395\n",
      "Epoch 36/500\n",
      "47696/47696 [==============================] - 24s 512us/step - loss: 0.0656 - acc: 0.9738 - val_loss: 0.3151 - val_acc: 0.9262\n",
      "Epoch 37/500\n",
      "47696/47696 [==============================] - 24s 509us/step - loss: 0.0617 - acc: 0.9761 - val_loss: 0.2892 - val_acc: 0.9333\n",
      "Epoch 38/500\n",
      "47696/47696 [==============================] - 24s 508us/step - loss: 0.0634 - acc: 0.9760 - val_loss: 0.2477 - val_acc: 0.9349\n",
      "Epoch 39/500\n",
      "47696/47696 [==============================] - 24s 505us/step - loss: 0.0603 - acc: 0.9766 - val_loss: 0.2864 - val_acc: 0.9337\n",
      "Epoch 40/500\n",
      "47696/47696 [==============================] - 23s 491us/step - loss: 0.0570 - acc: 0.9774 - val_loss: 0.3053 - val_acc: 0.9257\n",
      "Epoch 41/500\n",
      "47696/47696 [==============================] - 19s 406us/step - loss: 0.0578 - acc: 0.9776 - val_loss: 0.2717 - val_acc: 0.9307\n",
      "Epoch 42/500\n",
      "47696/47696 [==============================] - 19s 388us/step - loss: 0.0553 - acc: 0.9789 - val_loss: 0.2698 - val_acc: 0.9344\n",
      "Epoch 43/500\n",
      "47696/47696 [==============================] - 19s 390us/step - loss: 0.0561 - acc: 0.9784 - val_loss: 0.2230 - val_acc: 0.9392\n",
      "Epoch 44/500\n",
      "47696/47696 [==============================] - 19s 390us/step - loss: 0.0515 - acc: 0.9801 - val_loss: 0.2878 - val_acc: 0.9294\n",
      "Epoch 45/500\n",
      "40400/47696 [========================>.....] - ETA: 2s - loss: 0.0513 - acc: 0.9802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47696/47696 [==============================] - 19s 389us/step - loss: 0.0454 - acc: 0.9823 - val_loss: 0.3223 - val_acc: 0.9291\n",
      "Epoch 54/500\n",
      "47696/47696 [==============================] - 19s 389us/step - loss: 0.0427 - acc: 0.9827 - val_loss: 0.3332 - val_acc: 0.9311\n",
      "Epoch 55/500\n",
      "47696/47696 [==============================] - 19s 390us/step - loss: 0.0414 - acc: 0.9841 - val_loss: 0.3242 - val_acc: 0.9327\n",
      "Epoch 56/500\n",
      "47696/47696 [==============================] - 19s 392us/step - loss: 0.0406 - acc: 0.9845 - val_loss: 0.3871 - val_acc: 0.9194\n",
      "Epoch 57/500\n",
      "47696/47696 [==============================] - 19s 391us/step - loss: 0.0390 - acc: 0.9853 - val_loss: 0.3616 - val_acc: 0.9357\n",
      "Epoch 58/500\n",
      "47696/47696 [==============================] - 19s 390us/step - loss: 0.0394 - acc: 0.9846 - val_loss: 0.4131 - val_acc: 0.9263\n",
      "Epoch 59/500\n",
      " 7200/47696 [===>..........................] - ETA: 12s - loss: 0.0330 - acc: 0.9863"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "batch_size = 200\n",
    "epochs = 500\n",
    "optimizer = optimizers.Adam()\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400, activation=('relu'), use_bias=True))\n",
    "model.add(Dense(100, activation=('relu'), use_bias=True))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0, write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "#earlyStopper = EarlyStopping(monitor='acc', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, tg_callback])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"2312.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    optimizer = optimizers.Adam(lr=0.001)\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    #init=tf.global_variables_initializer()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    ####TENSORBOARD\n",
    "    config = \"\"\n",
    "    for layer in model.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "     \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "\n",
    "#set early stopping criteria\n",
    "pat = 5 #this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0, write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "model_checkpoint = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=500, BATCH_SIZE=500):\n",
    "    model = None\n",
    "    model = cnn_model()\n",
    "    model.summary()\n",
    "    history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, model_checkpoint, tg_callback, learning_rate_reduction])\n",
    "    \n",
    "    print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=3\n",
    "epochs=500\n",
    "batch_size=200\n",
    "\n",
    "#save the model history in a list after fitting so that we can plot later\n",
    "model_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    ####TODO\n",
    "    t_x, val_x, t_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    ####END\n",
    "    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracies vs Epochs')\n",
    "plt.plot(model_history[0].history['acc'], label='Training Fold 1')\n",
    "plt.plot(model_history[1].history['acc'], label='Training Fold 2')\n",
    "plt.plot(model_history[2].history['acc'], label='Training Fold 3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
