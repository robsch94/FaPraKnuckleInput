{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from scipy.odr import *\n",
    "from scipy.stats import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, LeavePOut\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'Jan_LSTM'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,14,15,16,17]\n",
    "test_ids = [4,5,6,11,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.TaskID = dfAll.TaskID % 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def detect_blobs(Blobs, TaskID):\n",
    "    image = Blobs\n",
    "    \n",
    "    #image = image.reshape(27, 15)\n",
    "    temp, thresh = cv2.threshold(cv2.bitwise_not(image), 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [a for a in contours if cv2.contourArea(a) > 8 and cv2.contourArea(a) < 255]\n",
    "    if len(contours) > 0:\n",
    "        if (TaskID not in [1, 6, 7]):\n",
    "            # only one blob\n",
    "            contours.sort(key=lambda a: cv2.contourArea(a))\n",
    "            max_contour = contours[-1]\n",
    "            \n",
    "            for (x, y) in max_contour.reshape(-1,2):\n",
    "                plt.plot(x, y, \"o\", color=\"r\")\n",
    "            plt.imshow(Blobs)\n",
    "            \n",
    "            xmax, ymax = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin, ymin = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            \n",
    "            return 15-xmax, 27-ymax, xmin, ymin\n",
    "        else:\n",
    "            # two blobs\n",
    "            blobs = []\n",
    "            contours.sort(key=lambda a: cv2.contourArea(a))\n",
    "            max_contour = contours[-1]\n",
    "            \n",
    "            for (x, y) in max_contour.reshape(-1,2):\n",
    "                plt.plot(x, y, \"o\", color=\"r\")\n",
    "            plt.imshow(Blobs)\n",
    "                \n",
    "            xmax, ymax = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin, ymin = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "\n",
    "            max_contour = contours[-2]\n",
    "            xmax2, ymax2 = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin2, ymin2 = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            \n",
    "            return 15 - max(xmax, xmax2), 27 - max(ymax, ymax2), min(xmin, xmin2), min(ymin, ymin2)\n",
    "    else:\n",
    "        return 0,0,100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxOffset(Blobs, taskID):\n",
    "    \n",
    "    xmax = 0\n",
    "    ymax = 0\n",
    "    xmin = 100\n",
    "    ymin = 100\n",
    "    for blob in Blobs:\n",
    "        blob = blob.reshape(27,15)\n",
    "        blob *= 255.0\n",
    "        blob = np.round(blob)\n",
    "        blob = blob.astype(np.uint8)\n",
    "        #print(blob.min(), blob.max())\n",
    "        _xmax, _ymax, _xmin, _ymin = detect_blobs(blob, taskID)\n",
    "        \n",
    "        xmax = max(xmax, _xmax)\n",
    "        ymax = max(ymax, _ymax)\n",
    "        xmin = min(xmin, _xmin)\n",
    "        ymin = min(ymin, _ymin)\n",
    "    \n",
    "    print(xmin, xmax, ymin, ymax)\n",
    "    #BlobSum = np.sum(Blobs, keepdims=True, axis=0).reshape(27,15)\n",
    "    #BlobSum *= 255.0/BlobSum.max() \n",
    "    #BlobSum = np.round(BlobSum)\n",
    "    #BlobSum = BlobSum.astype(np.uint8)\n",
    "    \n",
    "\n",
    "     #np.sqrt(784) = 28\n",
    "    \n",
    "    #hor_sum = np.sum(BlobSum, axis=0)\n",
    "    #hor_sum *= 255.0/hor_sum.max()\n",
    "    #print(\"HOR\", hor_sum)\n",
    "    #hor_std = np.std(hor_sum)\n",
    "    #hor_mean = np.mean(hor_sum)\n",
    "    #print(\"STD_hor: \", hor_std, \"MEAN:\", hor_mean)\n",
    "    #hor_thresh = hor_mean - hor_std\n",
    "    #for h in range(len(hor_sum)):\n",
    "    #    if (hor_sum[h] > hor_thresh):\n",
    "    #        print(\"hor_front_thresh: \", h)\n",
    "    #        break\n",
    "    #for h2 in range(len(hor_sum)):\n",
    "    #    if (hor_sum[-h2] > hor_thresh):\n",
    "    #        print(\"hor_back_thresh: \", h2)\n",
    "    #        break\n",
    "    #ver_sum = np.sum(BlobSum, axis=1)\n",
    "    #print(\"VER\", ver_sum)\n",
    "    #ver_std = np.std(ver_sum)\n",
    "    #ver_mean = np.mean(ver_sum)\n",
    "    #print(\"STD_ver:\", ver_std, \"MEAN: \", ver_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 5 12 11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "asdf = x_train[0].copy()\n",
    "getMaxOffset(asdf, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method to move one blob given from moveBlobs\n",
    "## First moves in x direction, second in y direction\n",
    "## Can also not move the blobs in any way if randints are 0\n",
    "def moveBlob(blob, x_direction, y_direction, x_offset_left, x_offset_right, y_offset_left, y_offset_right):\n",
    "    tmp = blob\n",
    "    if (x_direction == 0):\n",
    "        if (x_offset_left == 0): \n",
    "            tmp = np.pad(tmp,((0,0),(x_offset_left,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,0),(x_offset_left,0)), mode='constant')[:, :-x_offset_left]\n",
    "    elif (x_direction == 1):\n",
    "        if (x_offset_right == 0): \n",
    "            tmp = np.pad(tmp,((0,0),(0,x_offset_right)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,0),(0,x_offset_right)), mode='constant')[:, x_offset_right:]\n",
    "\n",
    "\n",
    "    if (y_direction == 0):\n",
    "        if (y_offset_left == 0): \n",
    "            tmp = np.pad(tmp,((y_offset_left,0),(0,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((y_offset_left,0),(0,0)), mode='constant')[:-y_offset_left, :]\n",
    "    elif (y_direction == 1):\n",
    "        if (y_offset_right == 0): \n",
    "            tmp = np.pad(tmp,((0,y_offset_right),(0,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,y_offset_right),(0,0)), mode='constant')[y_offset_right:, :]  \n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates randoms for x and y movement and calls moveBlobs method for each blob in Blobs\n",
    "## Return numpy array of same shape as input\n",
    "from random import randint\n",
    "def moveBlobs(Blobs):\n",
    "    print(Blobs.shape)\n",
    "    x_direction = randint(0,1)\n",
    "    y_direction = randint(0,1)\n",
    "    \n",
    "    ##Change the 2 to the min of given contour area or 4\n",
    "    x_offset_left = randint(0,2)\n",
    "    x_offset_right = randint(0,2)\n",
    "    \n",
    "    y_offset_left = randint(0,2)\n",
    "    y_offset_right = randint(0,2)\n",
    "    moved_blobs = []\n",
    "    if (x_offset_left == 0 and x_offset_right == 0 and y_offset_left == 0 and y_offset_right == 0):\n",
    "        print(\"No moving\")\n",
    "        moved_blobs = Blobs\n",
    "    else:\n",
    "        for i in range(len(Blobs)):\n",
    "            current_blob = Blobs[i].reshape(27,15)\n",
    "            moved_blob = moveBlob(current_blob, x_direction, y_direction, x_offset_left, x_offset_right, y_offset_left, y_offset_right)\n",
    "            moved_blob = moved_blob.reshape(27,15,1)\n",
    "            moved_blobs.append(moved_blob)\n",
    "        moved_blobs = np.array(moved_blobs)\n",
    "        \n",
    "        \n",
    "    return moved_blobs\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns images\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pSensors = hdf[set_name + \"/sensors\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pSensors.shape[0]\n",
    "    \n",
    "    randomBatchOrder = np.arange(len_train // batch_size)\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(len_train // batch_size):\n",
    "            idx = randomBatchOrder[i]\n",
    "            shuffled = shuffle(pSensors[idx * batch_size: (idx+1) * batch_size], pLabels[idx * batch_size: (idx+1) * batch_size])\n",
    "            yield shuffled[0].reshape(-1, train_x.shape[1], train_x.shape[2]), shuffled[1].reshape(-1, train_y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "epochs = 10000\n",
    "timesteps = 50\n",
    "data_dim = (27,15)\n",
    "l1v = 0.005\n",
    "l2v = 0.03\n",
    "\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)), input_shape=(timesteps ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                                 kernel_regularizer=regularizers.l1_l2(l1v,l2v))))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(3,3), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.40)))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)), input_shape=(timesteps ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                                 kernel_regularizer=regularizers.l1_l2(l1v,l2v))))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(TimeDistributed(Dense(128)))\n",
    "model.add(TimeDistributed(Dense(64)))\n",
    "#model.add(TimeDistributed(Dense(32)))\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(0.001,0.01)))\n",
    "#model.add(Dense(512))\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "#model.add(Dropout(0.20))\n",
    "#model.add(Dense(256))\n",
    "#model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(Dropout(0.20))\n",
    "#model.add(Dense(64))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adagrad()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Broadcast progress to the tensorboard.\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\" \n",
    "config += \"l1: \" + str(l1v) + \"\\n\\n\" + \"l2: \" + str(l2v) + \"\\n\\n\"\n",
    "\n",
    "model.summary()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_LSTM_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_LSTM_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=100, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_05_02_19_w50_b50_e1000_.l10001_l20005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=30)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
