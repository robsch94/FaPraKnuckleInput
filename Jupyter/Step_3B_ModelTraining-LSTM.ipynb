{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from scipy.odr import *\n",
    "from scipy.stats import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, LeavePOut\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'Jan_LSTM'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,14,15,16,17]\n",
    "test_ids = [4,5,6,11,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.TaskID = dfAll.TaskID % 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def detect_blobs(Blobs, TaskID):\n",
    "    image = Blobs\n",
    "    \n",
    "    #image = image.reshape(27, 15)\n",
    "    temp, thresh = cv2.threshold(cv2.bitwise_not(image), 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [a for a in contours if cv2.contourArea(a) > 8 and cv2.contourArea(a) < 255]\n",
    "    if len(contours) > 0:\n",
    "        if (TaskID not in [1, 6, 7]):\n",
    "            # only one blob\n",
    "            contours.sort(key=lambda a: cv2.contourArea(a))\n",
    "            max_contour = contours[-1]\n",
    "            \n",
    "            for (x, y) in max_contour.reshape(-1,2):\n",
    "                plt.plot(x, y, \"o\", color=\"r\")\n",
    "            plt.imshow(Blobs)\n",
    "            \n",
    "            xmax, ymax = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin, ymin = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            \n",
    "            return 15-xmax, 27-ymax, xmin, ymin\n",
    "        else:\n",
    "            # two blobs\n",
    "            blobs = []\n",
    "            contours.sort(key=lambda a: cv2.contourArea(a))\n",
    "            max_contour = contours[-1]\n",
    "            \n",
    "            for (x, y) in max_contour.reshape(-1,2):\n",
    "                plt.plot(x, y, \"o\", color=\"r\")\n",
    "            plt.imshow(Blobs)\n",
    "                \n",
    "            xmax, ymax = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin, ymin = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "\n",
    "            max_contour = contours[-2]\n",
    "            xmax2, ymax2 = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin2, ymin2 = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            \n",
    "            return 15 - max(xmax, xmax2), 27 - max(ymax, ymax2), min(xmin, xmin2), min(ymin, ymin2)\n",
    "    else:\n",
    "        return 0,0,100,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxOffset(Blobs, taskID):\n",
    "    \n",
    "    xmax = 0\n",
    "    ymax = 0\n",
    "    xmin = 100\n",
    "    ymin = 100\n",
    "    for blob in Blobs:\n",
    "        blob = blob.reshape(27,15)\n",
    "        blob *= 255.0\n",
    "        blob = np.round(blob)\n",
    "        blob = blob.astype(np.uint8)\n",
    "        #print(blob.min(), blob.max())\n",
    "        _xmax, _ymax, _xmin, _ymin = detect_blobs(blob, taskID)\n",
    "        \n",
    "        xmax = max(xmax, _xmax)\n",
    "        ymax = max(ymax, _ymax)\n",
    "        xmin = min(xmin, _xmin)\n",
    "        ymin = min(ymin, _ymin)\n",
    "    \n",
    "    print(xmin, xmax, ymin, ymax)\n",
    "    #BlobSum = np.sum(Blobs, keepdims=True, axis=0).reshape(27,15)\n",
    "    #BlobSum *= 255.0/BlobSum.max() \n",
    "    #BlobSum = np.round(BlobSum)\n",
    "    #BlobSum = BlobSum.astype(np.uint8)\n",
    "    \n",
    "\n",
    "     #np.sqrt(784) = 28\n",
    "    \n",
    "    #hor_sum = np.sum(BlobSum, axis=0)\n",
    "    #hor_sum *= 255.0/hor_sum.max()\n",
    "    #print(\"HOR\", hor_sum)\n",
    "    #hor_std = np.std(hor_sum)\n",
    "    #hor_mean = np.mean(hor_sum)\n",
    "    #print(\"STD_hor: \", hor_std, \"MEAN:\", hor_mean)\n",
    "    #hor_thresh = hor_mean - hor_std\n",
    "    #for h in range(len(hor_sum)):\n",
    "    #    if (hor_sum[h] > hor_thresh):\n",
    "    #        print(\"hor_front_thresh: \", h)\n",
    "    #        break\n",
    "    #for h2 in range(len(hor_sum)):\n",
    "    #    if (hor_sum[-h2] > hor_thresh):\n",
    "    #        print(\"hor_back_thresh: \", h2)\n",
    "    #        break\n",
    "    #ver_sum = np.sum(BlobSum, axis=1)\n",
    "    #print(\"VER\", ver_sum)\n",
    "    #ver_std = np.std(ver_sum)\n",
    "    #ver_mean = np.mean(ver_sum)\n",
    "    #print(\"STD_ver:\", ver_std, \"MEAN: \", ver_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = x_train[0].copy()\n",
    "getMaxOffset(asdf, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method to move one blob given from moveBlobs\n",
    "## First moves in x direction, second in y direction\n",
    "## Can also not move the blobs in any way if randints are 0\n",
    "def moveBlob(blob, x_direction, y_direction, x_offset_left, x_offset_right, y_offset_left, y_offset_right):\n",
    "    tmp = blob\n",
    "    if (x_direction == 0):\n",
    "        if (x_offset_left == 0): \n",
    "            tmp = np.pad(tmp,((0,0),(x_offset_left,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,0),(x_offset_left,0)), mode='constant')[:, :-x_offset_left]\n",
    "    elif (x_direction == 1):\n",
    "        if (x_offset_right == 0): \n",
    "            tmp = np.pad(tmp,((0,0),(0,x_offset_right)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,0),(0,x_offset_right)), mode='constant')[:, x_offset_right:]\n",
    "\n",
    "\n",
    "    if (y_direction == 0):\n",
    "        if (y_offset_left == 0): \n",
    "            tmp = np.pad(tmp,((y_offset_left,0),(0,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((y_offset_left,0),(0,0)), mode='constant')[:-y_offset_left, :]\n",
    "    elif (y_direction == 1):\n",
    "        if (y_offset_right == 0): \n",
    "            tmp = np.pad(tmp,((0,y_offset_right),(0,0)), mode='constant')[:, :]\n",
    "        else:\n",
    "            tmp = np.pad(tmp,((0,y_offset_right),(0,0)), mode='constant')[y_offset_right:, :]  \n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates randoms for x and y movement and calls moveBlobs method for each blob in Blobs\n",
    "## Return numpy array of same shape as input\n",
    "from random import randint\n",
    "def moveBlobs(Blobs):\n",
    "    print(Blobs.shape)\n",
    "    x_direction = randint(0,1)\n",
    "    y_direction = randint(0,1)\n",
    "    \n",
    "    ##Change the 2 to the min of given contour area or 4\n",
    "    x_offset_left = randint(0,2)\n",
    "    x_offset_right = randint(0,2)\n",
    "    \n",
    "    y_offset_left = randint(0,2)\n",
    "    y_offset_right = randint(0,2)\n",
    "    moved_blobs = []\n",
    "    if (x_offset_left == 0 and x_offset_right == 0 and y_offset_left == 0 and y_offset_right == 0):\n",
    "        print(\"No moving\")\n",
    "        moved_blobs = Blobs\n",
    "    else:\n",
    "        for i in range(len(Blobs)):\n",
    "            current_blob = Blobs[i].reshape(27,15)\n",
    "            moved_blob = moveBlob(current_blob, x_direction, y_direction, x_offset_left, x_offset_right, y_offset_left, y_offset_right)\n",
    "            moved_blob = moved_blob.reshape(27,15,1)\n",
    "            moved_blobs.append(moved_blob)\n",
    "        moved_blobs = np.array(moved_blobs)\n",
    "        \n",
    "        \n",
    "    return moved_blobs\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myGenerator(set_name, batch_size):\n",
    "    \"\"\"\n",
    "    This generator returns images\n",
    "    \"\"\"\n",
    "    hdf = h5py.File(HDF5_PATH, \"r\")\n",
    "\n",
    "    pSensors = hdf[set_name + \"/sensors\"]\n",
    "    pLabels = hdf[set_name + \"/labels\"]\n",
    "\n",
    "    len_train = pSensors.shape[0]\n",
    "    \n",
    "    randomBatchOrder = np.arange(len_train // batch_size)\n",
    "\n",
    "    while True:\n",
    "        np.random.shuffle(randomBatchOrder) \n",
    "        \n",
    "        for i in range(len_train // batch_size):\n",
    "            idx = randomBatchOrder[i]\n",
    "            shuffled = shuffle(pSensors[idx * batch_size: (idx+1) * batch_size], pLabels[idx * batch_size: (idx+1) * batch_size])\n",
    "            yield shuffled[0].reshape(-1, train_x.shape[1], train_x.shape[2]), shuffled[1].reshape(-1, train_y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "epochs = 10000\n",
    "timesteps = 50\n",
    "data_dim = (27,15)\n",
    "l1v = 0.005\n",
    "l2v = 0.03\n",
    "\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)), input_shape=(timesteps ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                                 kernel_regularizer=regularizers.l1_l2(l1v,l2v))))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(3,3), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.40)))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)), input_shape=(timesteps ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                                 kernel_regularizer=regularizers.l1_l2(l1v,l2v))))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(TimeDistributed(Dense(128)))\n",
    "model.add(TimeDistributed(Dense(64)))\n",
    "#model.add(TimeDistributed(Dense(32)))\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(0.001,0.01)))\n",
    "#model.add(Dense(512))\n",
    "model.add(LSTM(64, return_sequences=False, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "#model.add(Dropout(0.20))\n",
    "#model.add(Dense(256))\n",
    "#model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(Dropout(0.20))\n",
    "#model.add(Dense(64))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adagrad()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Broadcast progress to the tensorboard.\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\" \n",
    "config += \"l1: \" + str(l1v) + \"\\n\\n\" + \"l2: \" + str(l2v) + \"\\n\\n\"\n",
    "\n",
    "model.summary()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_LSTM_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_LSTM_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=100, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_05_02_19_w50_b50_e1000_.l10001_l20005.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=30)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
