{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'JAN_LSTM'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14,15,16,17]\n",
    "test_ids = [4,5,6,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dfAll.TaskID[dfAll.TaskID>=17] = dfAll.TaskID - 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNew = dfAll[dfAll.TaskID.isin([0, 2, 4,6,8,9,10,11,13,15])].copy()\n",
    "#y = pd.Series([0, 2, 4,6,8,9,10,11,13,15], index=[0,1,2,3,4,5,6,7,8,9])\n",
    "#dfNew.TaskID = dfNew.TaskID.replace([0, 2, 4,6,8,9,10,11,13,15], [0,1,2,3,4,5,6,7,8,9])\n",
    "#dfAll = dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_25 (TimeDis (None, 50, 27, 15, 32)    320       \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 50, 27, 15, 32)    9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 50, 3584)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 50, 512)           8390656   \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 17)                8721      \n",
      "=================================================================\n",
      "Total params: 10,508,145\n",
      "Trainable params: 10,508,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_LSTM_Jan_20190125_111527\n",
      "Train on 6125 samples, validate on 1963 samples\n",
      "Epoch 1/100\n",
      "6125/6125 [==============================] - 34s 6ms/step - loss: 25.9500 - acc: 0.1672 - val_loss: 17.2495 - val_acc: 0.2888\n",
      "Epoch 2/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 12.6435 - acc: 0.4521 - val_loss: 9.6577 - val_acc: 0.5043\n",
      "Epoch 3/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 7.5918 - acc: 0.6586 - val_loss: 6.6220 - val_acc: 0.6322\n",
      "Epoch 4/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 5.2982 - acc: 0.7796 - val_loss: 5.0055 - val_acc: 0.7229\n",
      "Epoch 5/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 4.0784 - acc: 0.8446 - val_loss: 4.0482 - val_acc: 0.7896\n",
      "Epoch 6/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 3.3499 - acc: 0.8785 - val_loss: 3.4604 - val_acc: 0.8151\n",
      "Epoch 7/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 2.8636 - acc: 0.8950 - val_loss: 3.2508 - val_acc: 0.7774\n",
      "Epoch 8/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 2.5390 - acc: 0.9012 - val_loss: 2.8702 - val_acc: 0.8207\n",
      "Epoch 9/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 2.2577 - acc: 0.9202 - val_loss: 2.6423 - val_acc: 0.8192\n",
      "Epoch 10/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 2.0518 - acc: 0.9234 - val_loss: 2.4371 - val_acc: 0.8268\n",
      "Epoch 11/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.8445 - acc: 0.9373 - val_loss: 2.3099 - val_acc: 0.8293\n",
      "Epoch 12/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.7305 - acc: 0.9316 - val_loss: 2.1918 - val_acc: 0.8283\n",
      "Epoch 13/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 1.5822 - acc: 0.9438 - val_loss: 2.0136 - val_acc: 0.8278\n",
      "Epoch 14/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.4695 - acc: 0.9461 - val_loss: 1.9083 - val_acc: 0.8507\n",
      "Epoch 15/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 1.3711 - acc: 0.9464 - val_loss: 1.8956 - val_acc: 0.8273\n",
      "Epoch 16/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 1.2824 - acc: 0.9505 - val_loss: 1.8839 - val_acc: 0.8304\n",
      "Epoch 17/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.2095 - acc: 0.9504 - val_loss: 1.7439 - val_acc: 0.8421\n",
      "Epoch 18/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 1.1090 - acc: 0.9592 - val_loss: 1.7177 - val_acc: 0.8365\n",
      "Epoch 19/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.0560 - acc: 0.9576 - val_loss: 1.7323 - val_acc: 0.8232\n",
      "Epoch 20/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 1.0502 - acc: 0.9505 - val_loss: 1.6405 - val_acc: 0.8192\n",
      "Epoch 21/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 1.0202 - acc: 0.9464 - val_loss: 1.5840 - val_acc: 0.8406\n",
      "Epoch 22/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.8971 - acc: 0.9662 - val_loss: 1.5187 - val_acc: 0.8375\n",
      "Epoch 23/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.8922 - acc: 0.9551 - val_loss: 1.4352 - val_acc: 0.8553\n",
      "Epoch 24/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.8341 - acc: 0.9620 - val_loss: 1.4937 - val_acc: 0.8426\n",
      "Epoch 25/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.7918 - acc: 0.9662 - val_loss: 1.4375 - val_acc: 0.8273\n",
      "Epoch 26/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.7694 - acc: 0.9638 - val_loss: 1.3383 - val_acc: 0.8497\n",
      "Epoch 27/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.7250 - acc: 0.9670 - val_loss: 1.4358 - val_acc: 0.8263\n",
      "Epoch 28/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.7068 - acc: 0.9660 - val_loss: 1.3484 - val_acc: 0.8319\n",
      "Epoch 29/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.6895 - acc: 0.9654 - val_loss: 1.3554 - val_acc: 0.8426\n",
      "Epoch 30/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.6488 - acc: 0.9703 - val_loss: 1.3009 - val_acc: 0.8400\n",
      "Epoch 31/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.6397 - acc: 0.9665 - val_loss: 1.2975 - val_acc: 0.8314\n",
      "Epoch 32/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.6502 - acc: 0.9608 - val_loss: 1.1922 - val_acc: 0.8528\n",
      "Epoch 33/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.6097 - acc: 0.9687 - val_loss: 1.2262 - val_acc: 0.8482\n",
      "Epoch 34/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.5747 - acc: 0.9724 - val_loss: 1.2557 - val_acc: 0.8436\n",
      "Epoch 35/100\n",
      "6125/6125 [==============================] - 31s 5ms/step - loss: 0.5845 - acc: 0.9660 - val_loss: 1.2397 - val_acc: 0.8472\n",
      "Epoch 36/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.5431 - acc: 0.9716 - val_loss: 1.1419 - val_acc: 0.8599\n",
      "Epoch 37/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.5166 - acc: 0.9750 - val_loss: 1.1821 - val_acc: 0.8594\n",
      "Epoch 38/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4985 - acc: 0.9780 - val_loss: 1.1766 - val_acc: 0.8507\n",
      "Epoch 39/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4943 - acc: 0.9744 - val_loss: 1.1253 - val_acc: 0.8416\n",
      "Epoch 40/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.5001 - acc: 0.9704 - val_loss: 1.0907 - val_acc: 0.8579\n",
      "Epoch 41/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4712 - acc: 0.9752 - val_loss: 1.0891 - val_acc: 0.8538\n",
      "Epoch 42/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4537 - acc: 0.9781 - val_loss: 1.1099 - val_acc: 0.8456\n",
      "Epoch 43/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4410 - acc: 0.9775 - val_loss: 1.0745 - val_acc: 0.8645\n",
      "Epoch 44/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4443 - acc: 0.9753 - val_loss: 1.1368 - val_acc: 0.8512\n",
      "Epoch 45/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4348 - acc: 0.9753 - val_loss: 1.1240 - val_acc: 0.8395\n",
      "Epoch 46/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4143 - acc: 0.9799 - val_loss: 1.0766 - val_acc: 0.8533\n",
      "Epoch 47/100\n",
      "6125/6125 [==============================] - 32s 5ms/step - loss: 0.4759 - acc: 0.9618 - val_loss: 1.1250 - val_acc: 0.8446\n",
      "Epoch 48/100\n",
      "3720/6125 [=================>............] - ETA: 11s - loss: 0.4214 - acc: 0.9833"
     ]
    }
   ],
   "source": [
    "batch_size = 60\n",
    "epochs = 100\n",
    "timesteps = 50\n",
    "data_dim = (27,15)\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l2(0.01)), input_shape=(50 ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.50)))\n",
    "\n",
    "#model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "#model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "#model.add(TimeDistributed(Dropout(0.50)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(timesteps, data_dim), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(TimeDistributed(Dropout(0.50)))\n",
    "model.add(LSTM(512, kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adagrad()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Broadcast progress to the tensorboard.\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "model.summary()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_LSTM_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_LSTM_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=20, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.save('lstm_23_01_19.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
