{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14,15,16]\n",
    "test_ids = [4,5,6,11,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "dfAll['InputMethod'] = dfAll.apply(f, axis=1)\n",
    "dfAll.TaskID = dfAll.TaskID % 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfAll[\"TaskID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [i for i in range(17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 17 artists>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(h,dfAll[[\"userID\", \"TaskID\"]].groupby([\"TaskID\"])[\"TaskID\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"ModelSnapshots/KnuckleFinger_LSTM_Jan_20190203_230639.h5\", compile=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_38 (TimeDis (None, 50, 27, 15, 32)    320       \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 50, 27, 15, 32)    9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 50, 3584)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 50, 128)           458880    \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 50, 64)            8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 50, 32)            2080      \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 50, 512)           1116160   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                147712    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 17)                1105      \n",
      "=================================================================\n",
      "Total params: 1,743,761\n",
      "Trainable params: 1,743,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "plot_model(model,to_file='demo.pdf',show_shapes=True, show_layer_names=False, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of the precision, recall, F1 score for each class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78       129\n",
      "           1       0.99      0.89      0.94       167\n",
      "           2       0.98      0.85      0.91       139\n",
      "           3       0.88      0.78      0.82       117\n",
      "           4       0.88      0.87      0.88       139\n",
      "           5       0.89      0.82      0.85       141\n",
      "           6       0.98      0.98      0.98       161\n",
      "           7       0.98      0.98      0.98       167\n",
      "           8       0.78      0.98      0.87       140\n",
      "           9       0.88      0.92      0.90       150\n",
      "          10       0.95      0.91      0.93       145\n",
      "          11       0.92      0.94      0.93       144\n",
      "          12       0.81      0.85      0.83       159\n",
      "          13       0.88      0.94      0.91       158\n",
      "          14       0.77      0.89      0.83       160\n",
      "          15       0.90      0.92      0.91       162\n",
      "          16       0.80      0.90      0.85       101\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2479\n",
      "   macro avg       0.89      0.89      0.89      2479\n",
      "weighted avg       0.90      0.89      0.89      2479\n",
      "\n",
      "\n",
      " Confusion matrix: \n",
      "[[ 86   0   0   4   3   7   0   0   2   4   1   2   8   1   0   1  10]\n",
      " [  0 149   0   1   1   0   1   1   1   8   1   0   3   0   0   0   1]\n",
      " [  0   0 118   1   0   0   0   0   4   0   0   0   2   0  13   1   0]\n",
      " [  0   0   0  91   0   0   0   0   0   1   0   2   7  16   0   0   0]\n",
      " [  0   0   0   0 121   0   1   0   4   0   0   2   7   0   3   0   1]\n",
      " [  1   0   0   0   0 116   0   0   0   1   0   0   1   0  21   0   1]\n",
      " [  0   0   0   0   0   0 158   1   0   0   0   1   0   0   1   0   0]\n",
      " [  0   1   0   0   0   2   0 163   0   0   0   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0 137   2   0   0   0   1   0   0   0]\n",
      " [  0   0   1   2   0   0   0   0   2 138   0   2   0   2   0   3   0]\n",
      " [  0   0   0   2   0   1   0   0   3   2 132   0   0   0   0   5   0]\n",
      " [  0   0   0   1   4   0   0   0   3   0   0 135   0   0   0   0   1]\n",
      " [  0   0   0   1   4   0   1   1  11   0   0   1 135   0   0   1   4]\n",
      " [  0   0   0   1   0   1   0   1   2   0   0   0   2 148   1   0   2]\n",
      " [  0   0   2   0   2   2   0   0   2   0   4   0   1   0 142   4   1]\n",
      " [  0   0   0   0   0   0   0   0   4   1   1   1   0   1   3 149   2]\n",
      " [  5   1   0   0   2   2   0   0   0   0   0   0   0   0   0   0  91]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=50)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of the precision, recall, F1 score for each class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       129\n",
      "           1       0.05      0.04      0.04       167\n",
      "           2       0.00      0.00      0.00       139\n",
      "           3       0.04      0.07      0.05       117\n",
      "           4       0.08      0.01      0.01       139\n",
      "           5       0.04      0.02      0.03       141\n",
      "           6       0.03      0.02      0.03       161\n",
      "           7       0.11      0.16      0.13       167\n",
      "           8       0.09      0.06      0.07       140\n",
      "           9       0.03      0.01      0.02       150\n",
      "          10       0.02      0.01      0.02       145\n",
      "          11       0.11      0.07      0.08       144\n",
      "          12       0.06      0.14      0.08       159\n",
      "          13       0.01      0.01      0.01       158\n",
      "          14       0.10      0.07      0.08       160\n",
      "          15       0.01      0.01      0.01       162\n",
      "          16       0.06      0.17      0.09       101\n",
      "\n",
      "   micro avg       0.05      0.05      0.05      2479\n",
      "   macro avg       0.05      0.05      0.04      2479\n",
      "weighted avg       0.05      0.05      0.04      2479\n",
      "\n",
      "\n",
      " Confusion matrix: \n",
      "[[ 0  6  5  2  0 14  8  9  1  7  3  1 34  3  8 20  8]\n",
      " [ 5  6  7 30  1  2  6 16  3 14  2  7 35  6  6  6 15]\n",
      " [ 5  0  0 17  0  2  9 18  3  6  5  9 35 10  7  5  8]\n",
      " [ 5  0  2  8  1  0  3  7  0  4  0  7 67  0  7  0  6]\n",
      " [11  0 15  5  1  8  6  4  4  1  4  3  6  7  9 35 20]\n",
      " [ 5 20 26 10  1  3  9  6  5  0  5  4  2  2  1 13 29]\n",
      " [ 2  1  1 16  0  4  4  6  3  1  9  5 37 18 11 28 15]\n",
      " [ 2  7 15  9  1  4 18 26  9  1 23 14  7  1  9  3 18]\n",
      " [ 0  4  2 11  3  2  4 11  8  6  2  7 24 11  3 14 28]\n",
      " [ 4  5 12 25  0  4 29 13  6  2 10  2  2  6  9  2 19]\n",
      " [ 3 17  6 15  0  3  4  2 13  9  2  6 26  6  5 11 17]\n",
      " [ 0  1  1  5  0  0  1 16  0  8  0 10 44 14  5 19 20]\n",
      " [ 3  1  1 10  0  9  7  7  6  4 10  3 22 25  8 26 17]\n",
      " [ 3  9 19 11  0  7 13 28 14  0  2  6 25  1  9  4  7]\n",
      " [ 6 10 22  7  0  9  7 29  4  0  4  3  3  6 11  4 35]\n",
      " [ 0 22 11 12  3  6 19 37  6  1  5  2  6  6  5  2 19]\n",
      " [ 1  3  8  5  1  5  3  8  9  4  2  3 14  5  1 12 17]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=30)\n",
    "y_test_pred[0] = np.argmax(y_test_pred[0], axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred[0]))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
