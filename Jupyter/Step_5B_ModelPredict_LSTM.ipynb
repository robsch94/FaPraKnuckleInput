{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14,15,16]\n",
    "test_ids = [4,5,6,11,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "dfAll['InputMethod'] = dfAll.apply(f, axis=1)\n",
    "dfAll.TaskID = dfAll.TaskID % 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfAll[\"TaskID\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [i for i in range(17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 17 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(h,dfAll[[\"userID\", \"TaskID\"]].groupby([\"TaskID\"])[\"TaskID\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"lstm_05_02_19_w50_b50_e1000_.l10001_l20005.h5\", compile=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 50, 27, 15, 64)    640       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 50, 27, 15, 32)    18464     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 50, 9, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 50, 9, 5, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 50, 9, 5, 32)      9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 50, 9, 5, 16)      4624      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 50, 5, 3, 16)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 50, 240)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 50, 64)            15424     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 256)           328704    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                82176     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                1105      \n",
      "=================================================================\n",
      "Total params: 460,385\n",
      "Trainable params: 460,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "plot_model(model,to_file='demo.pdf',show_shapes=True, show_layer_names=False, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary of the precision, recall, F1 score for each class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       294\n",
      "           1       0.94      0.95      0.94       372\n",
      "           2       0.99      0.93      0.96       278\n",
      "           3       1.00      0.92      0.96       271\n",
      "           4       0.98      0.99      0.99       273\n",
      "           5       0.99      0.98      0.98       285\n",
      "           6       0.90      1.00      0.95       361\n",
      "           7       0.96      0.98      0.97       382\n",
      "           8       1.00      0.93      0.96       360\n",
      "           9       0.99      0.96      0.97       332\n",
      "          10       1.00      0.94      0.97       340\n",
      "          11       1.00      0.95      0.97       327\n",
      "          12       0.99      0.98      0.98       351\n",
      "          13       0.91      0.98      0.95       355\n",
      "          14       0.89      0.98      0.93       351\n",
      "          15       0.94      0.97      0.96       357\n",
      "          16       0.97      0.97      0.97       320\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5609\n",
      "   macro avg       0.97      0.96      0.96      5609\n",
      "weighted avg       0.96      0.96      0.96      5609\n",
      "\n",
      "\n",
      " Confusion matrix: \n",
      "[[275   1   0   0   3   1  13   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0 354   0   0   0   0  18   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 259   0   0   0   0   0   0   0   0   0   0   0  19   0   0]\n",
      " [  0   0   0 249   0   0   2   0   1   1   0   0   0  14   4   0   0]\n",
      " [  0   0   0   0 271   0   1   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   1   0   0   0 279   0   4   0   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0 361   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   4   0   0   0   3   0 375   0   0   0   0   0   0   0   0   0]\n",
      " [  1   5   0   0   0   0   4   0 336   0   0   0   1   6   6   0   1]\n",
      " [  0   0   1   0   0   0   0   0   0 318   0   0   0   7   2   0   4]\n",
      " [  0   1   0   0   0   0   0   5   0   0 318   0   0   0   3  12   1]\n",
      " [  1   7   0   0   0   0   1   0   0   0   0 311   1   6   0   0   0]\n",
      " [  0   0   1   0   2   0   0   0   0   1   0   1 345   0   0   1   0]\n",
      " [  1   0   0   0   0   0   0   4   0   1   0   0   1 348   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 343   8   0]\n",
      " [  1   0   0   0   0   0   0   1   0   0   0   0   0   0   3 348   4]\n",
      " [  0   5   0   0   0   0   1   0   0   0   0   0   0   0   3   0 311]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_test_pred = model.predict(x_train, batch_size=50)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_train, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_train, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=30)\n",
    "y_test_pred[0] = np.argmax(y_test_pred[0], axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred[0]))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
