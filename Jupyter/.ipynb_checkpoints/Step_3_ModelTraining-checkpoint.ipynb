{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.odr import *\n",
    "from scipy.stats import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, LeavePOut\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "df_train = dfAll[dfAll.userID != 6]\n",
    "df_test = dfAll[dfAll.userID == 6]\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "#Create InputMethod Column and fill it with Knuckel / Finger\n",
    "def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "df_train['InputMethod'] = df_train.apply(f, axis=1)\n",
    "df_test['InputMethod'] = df_test.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()\n",
    "\n",
    "def convert(row):\n",
    "    #print(row['Blobs'][0])\n",
    "    return row['Blobs'][0]\n",
    "    \n",
    "    \n",
    "df_train2['Blobs'] = df_train2.apply(convert, axis=1)\n",
    "df_test2['Blobs'] = df_test2.apply(convert, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(df_train2.Blobs[i][0]) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, df_train2.InputMethod[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 20)        200       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 20)        3620      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 8)         1448      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 9218      \n",
      "=================================================================\n",
      "Total params: 14,486\n",
      "Trainable params: 14,486\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_10_input to have 4 dimensions, but got array with shape (10, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-33a24e255b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     validation_data=(df_test2.Blobs[0], y_test_one_hot))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   1432\u001b[0m     y = _standardize_input_data(\n\u001b[1;32m   1433\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;34m'Error when checking '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             ' dimensions, but got array with shape ' + str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_10_input to have 4 dimensions, but got array with shape (10, 10)"
     ]
    }
   ],
   "source": [
    "########## HYPER PARAMETERS\n",
    "batch_size = 40\n",
    "epochs = 100\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "########## MODEL ARCHITECTURE\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "### OLD ARCHITECTURE START\n",
    "#model.add(tf.keras.layers.Dense(5, activation='relu', input_shape=(784,)))\n",
    "### OLD ARCHITECTURE END\n",
    "\n",
    "### NEW CNN ARCHITECTURE\n",
    "model.add(tf.keras.layers.Conv2D(20, kernel_size=(3, 3), activation='relu',padding='same', input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(8, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "### NEW CNN ARCHITECTURE\n",
    "\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(df_train2.Blobs[0], y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(df_test2.Blobs[0], y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"myModel.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
