{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'JAN_LSTM_CNN'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14,15,16,17]\n",
    "test_ids = [4,5,6,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm30.pkl\")\n",
    "dfCNN =  pd.read_pickle(\"PklData/df_blobs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.TaskID[dfAll.TaskID>=17] = dfAll.TaskID - 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNew = dfAll[dfAll.TaskID.isin([0, 2, 4,6,8,9,10,11,13,15])].copy()\n",
    "#y = pd.Series([0, 2, 4,6,8,9,10,11,13,15], index=[0,1,2,3,4,5,6,7,8,9])\n",
    "#dfNew.TaskID = dfNew.TaskID.replace([0, 2, 4,6,8,9,10,11,13,15], [0,1,2,3,4,5,6,7,8,9])\n",
    "#dfAll = dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train3 = dfCNN[dfCNN.userID.isin(train_ids)]\n",
    "df_test3 = dfCNN[dfCNN.userID.isin(test_ids) & (dfCNN.Version == \"Normal\")]\n",
    "\n",
    "\n",
    "df_train4 = df_train3[['Blobs', 'InputMethod']].copy()\n",
    "df_test4 = df_test3[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3 = np.vstack(df_train4.Blobs)\n",
    "x_test3 = np.vstack(df_test4.Blobs)\n",
    "y_train3 = df_train4.InputMethod.values\n",
    "y_test3 = df_test4.InputMethod.values\n",
    "\n",
    "x_train3 = x_train3.reshape(-1, 27, 15, 1)\n",
    "x_test3 = x_test3.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,30,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,30,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique()) \n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes_cnn = 2\n",
    "y_train_one_hot_cnn = utils.to_categorical(df_train3.InputMethod, num_classes_cnn)\n",
    "y_test_one_hot_cnn = utils.to_categorical(df_test3.InputMethod, num_classes_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "[node.op.name for node in KnuckelFinger.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KnuckelFinger.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = Model(inputs=KnuckelFinger.input, outputs=KnuckelFinger.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KnuckelFinger = load_model(\"10_01_19.h5\", compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(KnuckelFinger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = KnuckelFinger.predict_classes(x_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = x_train3[144].reshape((1,27,15,1))\n",
    "KnuckelFinger.predict_classes(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in range(len(a)) if a[i] ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "KnuckelFinger.summary()\n",
    "\n",
    "hist = KnuckelFinger.fit(x_test3, y_test_one_hot_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "data = np.zeros((1,784))\n",
    "labels = np.zeros((1,10))\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels)  # starts training\n",
    "\n",
    "x = Input(shape=(784,))\n",
    "# This works, and returns the 10-way softmax we defined above.\n",
    "y = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# Input tensor for sequences of 20 timesteps,\n",
    "# each containing a 784-dimensional vector\n",
    "input_sequences = Input(shape=(30,27,15,1))\n",
    "\n",
    "# This applies our previous model to every timestep in the input sequences.\n",
    "# the output of the previous model was a 10-way softmax,\n",
    "# so the output of the layer below will be a sequence of 20 vectors of size 10.\n",
    "model = Model(inputs = KnuckelFinger.layers[0].input, outputs = KnuckelFinger.layers[-1].output)\n",
    "processed_sequences = TimeDistributed(model)(input_sequences)\n",
    "model2 = Model(inputs=input_sequences, outputs=processed_sequences)\n",
    "type(model2)\n",
    "model2.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "import pydot\n",
    "\n",
    "batch_size = 60\n",
    "epochs = 100\n",
    "timesteps = 30\n",
    "data_dim = (27,15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "#### Gesture structure\n",
    "A0 = Input(shape=(30,27,15,1),name='A0')\n",
    "A1 = TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                            kernel_regularizer=regularizers.l2(0.01)),input_shape=(30, 27,15,1), name='A1')(A0)\n",
    "A2 = TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A2')(A1)\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "A3 = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'),name='A3')(A2)\n",
    "A4 = TimeDistributed(Dropout(0.20), name='A4')(A3)\n",
    "\n",
    "\n",
    "A5 = TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A5')(A4)\n",
    "A6 = TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A6')(A5)\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "A7 = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'),name='A7')(A6)\n",
    "A8 = TimeDistributed(Dropout(0.10), name='A8')(A7)\n",
    "\n",
    "A9 = TimeDistributed(Flatten(), name='A9')(A8)\n",
    "\n",
    "A10 = LSTM(128, return_sequences=True, input_shape=(timesteps, data_dim), name='A10', kernel_regularizer=regularizers.l2(0.01))(A9)\n",
    "A11 = LSTM(64, kernel_regularizer=regularizers.l2(0.01), name='A11')(A10)\n",
    "A12 = Dense(num_classes, activation='softmax', name='A12')(A11)\n",
    "A = Model(inputs=A0, outputs=A12)\n",
    "\n",
    "### END Gesture structure\n",
    "\n",
    "#print(KnuckelFinger.outputs[0])\n",
    "\n",
    "B0 = TimeDistributed(KnuckelFinger(), name='B0')(A0)\n",
    "#B1 = Reshape((27,15,-1),name='B1')(A0)\n",
    "\n",
    "#B2 = Conv2D(64 ,kernel_size=(3,3), input_shape=(30,27,15,1),activation='relu',name='B2')(B1)\n",
    "#B3 = Flatten(name='B3')(B2)\n",
    "#B3 = Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15),name='B3', use_bias=True)(B2)\n",
    "B4 = Dense(2, activation='softmax',name='B4')(B3)\n",
    "\n",
    "merged = Model(inputs=[A0],outputs=[A12, B3])\n",
    "#merged.add_weight(KnuckelFinger, shape=(27,15))\n",
    "merged.summary()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "merged.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "history = merged.fit(x_train, [y_train_one_hot, y_train_one_hot_cnn],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot))\n",
    "                        #callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n",
    "\n",
    "#plot_model(merged,to_file='demo.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "batch_size = 60\n",
    "epochs = 100\n",
    "timesteps = 30\n",
    "data_dim = (27,15)\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', kernel_regularizer=regularizers.l2(0.01)), input_shape=(30, 27,15,1)))\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.20)))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))))\n",
    "#model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.10)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(timesteps, data_dim), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "#### Finger Knuckle\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adagrad()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Broadcast progress to the tensorboard.\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "model.summary()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_LSTM_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_LSTM_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_LSTM_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=20, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.save('lstm_23_01_19.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
