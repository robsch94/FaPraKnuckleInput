{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.models import save_model, load_model\n",
    "import pydot\n",
    "\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'JAN_LSTM_CNN_CROSS'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14,15,16]\n",
    "test_ids = [4,5,6,11,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")\n",
    "dfCNN =  pd.read_pickle(\"PklData/df_blobs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "dfAll['InputMethod'] = dfAll.apply(f, axis=1)\n",
    "dfAll.TaskID = dfAll.TaskID % 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSets(train_ids, test_ids):\n",
    "    df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "    df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "    df_train2 = df_train[['Blobs', 'TaskID', 'InputMethod']].copy()\n",
    "    df_test2 = df_test[['Blobs', 'TaskID', 'InputMethod']].copy()\n",
    "    x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "    x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "    y_train = df_train2.TaskID.values\n",
    "    y_test = df_test2.TaskID.values\n",
    "\n",
    "    y_train_cnn = df_train2.InputMethod.values\n",
    "    y_test_cnn = df_train2.InputMethod.values\n",
    "\n",
    "    num_classes = len(dfAll.TaskID.unique()) \n",
    "    y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "    y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)\n",
    "    \n",
    "    # convert class vectors to binary class matrices (one-hot notation)\n",
    "    num_classes_cnn = 2\n",
    "    y_train_one_hot_cnn = utils.to_categorical(df_train2.InputMethod, num_classes_cnn)\n",
    "    y_test_one_hot_cnn = utils.to_categorical(df_test2.InputMethod, num_classes_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.allow_growth = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KnuckelFinger = load_model(\"10_01_19.h5\", compile=True)\n",
    "KnuckelFinger.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "epochs = 100\n",
    "timesteps = 50\n",
    "data_dim = (27,15)\n",
    "\n",
    "\n",
    "def gesture_model():\n",
    "\n",
    "    tf.get_default_graph()\n",
    "    model = Sequential()\n",
    "\n",
    "    #### Gesture structure\n",
    "    A0 = Input(shape=(50,27,15,1),name='A0')\n",
    "    A1 = TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                                kernel_regularizer=regularizers.l2(0.01)),input_shape=(50, 27,15,1), name='A1')(A0)\n",
    "    A2 = TimeDistributed(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A2')(A1)\n",
    "    #model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "    A3 = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'),name='A3')(A2)\n",
    "    A4 = TimeDistributed(Dropout(0.50), name='A4')(A3)\n",
    "\n",
    "\n",
    "    #A5 = TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A5')(A4)\n",
    "    #A6 = TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),name='A6')(A5)\n",
    "    #model.add(TimeDistributed(BatchNormalization(axis=-1)))\n",
    "    #A7 = TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'),name='A7')(A6)\n",
    "    #A8 = TimeDistributed(Dropout(0.50), name='A8')(A7)\n",
    "\n",
    "    A9 = TimeDistributed(Flatten(), name='A9')(A4)\n",
    "\n",
    "    A10 = LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim), name='A10', kernel_regularizer=regularizers.l2(0.01))(A9)\n",
    "    A11 = LSTM(128, kernel_regularizer=regularizers.l2(0.01), name='A11')(A10)\n",
    "    A12 = Dense(num_classes, activation='softmax', name='A12')(A11)\n",
    "    A = Model(inputs=A0, outputs=A12)\n",
    "    # Output is a (17,1) tensor which tells us about finger or knuckle input\n",
    "\n",
    "    ### END Gesture structure\n",
    "\n",
    "    #print(KnuckelFinger.outputs[0])\n",
    "    model = Model(inputs = KnuckelFinger.layers[0].input, outputs = KnuckelFinger.layers[-1].output)\n",
    "    B0 = TimeDistributed(model, name='B0')(A0)\n",
    "    B1 = Flatten(name=\"B1\")(B0)\n",
    "    B2 = Dense(2, activation='softmax', name='B2')(B1)\n",
    "    #B1 = Reshape((27,15,-1),name='B1')(A0)\n",
    "\n",
    "    #B2 = Conv2D(64 ,kernel_size=(3,3), input_shape=(30,27,15,1),activation='relu',name='B2')(B1)\n",
    "    #B3 = Flatten(name='B3')(B2)\n",
    "    #B3 = Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15),name='B3', use_bias=True)(B2)\n",
    "    #B3 = Dense(2, activation='softmax',name='B4')(B0)\n",
    "    # Output is a (2,1) tensor which tells us about finger or knuckle input\n",
    "    merged = Model(inputs=[A0],outputs=[A12, B2])\n",
    "    config = \"\"\n",
    "    for layer in merged.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "    #merged.add_weight(KnuckelFinger, shape=(27,15))\n",
    "    optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    merged.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_LSTM+CNN\" + readable_timestamp\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0, write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "model_checkpoint = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_LSTM+CNN\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_LSTM+CNN\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
    "\n",
    "def fit_and_evaluate(x_train, y_train_one_hot, x_test, x_test_one_hot, EPOCHS=500, BATCH_SIZE=500):\n",
    "    model = None\n",
    "    model = gesture_model()\n",
    "    model.summary()\n",
    "    history = merged.fit(x_train, [y_train_one_hot, y_train_one_hot_cnn],\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, [y_test_one_hot, y_test_one_hot_cnn]),\n",
    "                        callbacks=[storer, \n",
    "                                   logger,\n",
    "                                   tg_callback])\n",
    "    \n",
    "    #print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = dfAll.userID.unique()\n",
    "epochs=500\n",
    "batch_size=500\n",
    "\n",
    "#save the model history in a list after fitting so that we can plot later\n",
    "model_history = []\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "result_file = open(\"CrossValid/results_gestures_%s.csv\" % readable_timestamp, \"a\")\n",
    "result_file.write(\"TrainIds;TestIds;val_A12_acc;val_B2_acc;A12_acc;B2_acc\\n\")\n",
    "result_file.flush()\n",
    "\n",
    "for i in n_folds:\n",
    "    test_ids = [i]\n",
    "    \n",
    "    train_ids = np.setdiff1d(dfAll.userID.unique(), test_ids)\n",
    "     \n",
    "    print(\"Training on Fold: \",i, \"\\n test_ids: \", test_ids, \"\\n train_ids: \", train_ids)\n",
    "    x_train, y_train_one_hot, x_test, y_test_one_hot = createDataSets(train_ids, test_ids)\n",
    "    #t_x, val_x, t_y, val_y = train_test_split(x_train, y_train, test_size=0.1, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    ####END\n",
    "    cur_hist = fit_and_evaluate(x_train, y_train_one_hot, x_test, y_test_one_hot, epochs, batch_size)\n",
    "    model_history.append(cur_hist)\n",
    "    \n",
    "    hist_result = str(train_ids) + \";\" + str(test_ids) + \";\"\n",
    "    hist_result += str(cur_hist.history[\"val_A12_acc\"]) + \";\"\n",
    "    hist_result += str(cur_hist.history[\"val_B2_acc\"]) + \";\"\n",
    "    hist_result += str(cur_hist.history[\"A12_acc\"]) + \";\"\n",
    "    hist_result += str(cur_hist.history[\"B2_acc\"]) + \"\\n\"\n",
    "    \n",
    "    result_file.write(hist_result)\n",
    "    result_file.flush()\n",
    "    \n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")\n",
    "\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_A12_acc'], label=\"Test Accuracy LSTM\")\n",
    "plt.plot(history.history['val_B2_acc'], label=\"Test Accuracy CNN\")\n",
    "plt.plot(history.history['A12_acc'], label=\"Training Accuracy LSTM\")\n",
    "plt.plot(history.history['B2_acc'], label=\"Training Accuracy CNN\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    merged.save('lstm_cnn_27_01_19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = merged.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[0] = np.argmax(y_test_pred[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred[1] = np.argmax(y_test_pred[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred[0]))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred[1]))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
