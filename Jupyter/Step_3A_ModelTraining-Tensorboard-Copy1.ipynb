{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,   \n",
    "    'model_name': \"JAN_CNN05_2\" # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  8 11 15  7] [ 1  2  9  6  4 14 17 16 12  3 10 18  5]\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "\n",
    "lst = dfAll.userID.unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(lst)\n",
    "train_ids = lst[-5:]\n",
    "test_ids = lst[:-5]\n",
    "print(train_ids, test_ids)\n",
    "\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "#df_test = df_test.reset_index()\n",
    "#df_train = df_train.reset_index()\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 27, 15, 128)       1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 27, 15, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 8, 64)         36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 8, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                71760     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 206,698\n",
      "Trainable params: 206,122\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Jan_v2_20190225_143820\n",
      "Train on 93484 samples, validate on 73737 samples\n",
      "Epoch 1/15000\n",
      "93484/93484 [==============================] - 28s 297us/step - loss: 5.1566 - acc: 0.8570 - val_loss: 0.7253 - val_acc: 0.9040\n",
      "Epoch 2/15000\n",
      "93484/93484 [==============================] - 26s 273us/step - loss: 0.6569 - acc: 0.9111 - val_loss: 0.6261 - val_acc: 0.9093\n",
      "Epoch 3/15000\n",
      "93484/93484 [==============================] - 26s 280us/step - loss: 0.6038 - acc: 0.9158 - val_loss: 1.4224 - val_acc: 0.7394\n",
      "Epoch 4/15000\n",
      "93484/93484 [==============================] - 25s 272us/step - loss: 0.5779 - acc: 0.9198 - val_loss: 1.2258 - val_acc: 0.7624\n",
      "Epoch 5/15000\n",
      "93484/93484 [==============================] - 25s 272us/step - loss: 0.5624 - acc: 0.9225 - val_loss: 0.6813 - val_acc: 0.8924\n",
      "Epoch 6/15000\n",
      "93484/93484 [==============================] - 26s 273us/step - loss: 0.5507 - acc: 0.9228 - val_loss: 0.7477 - val_acc: 0.8792\n",
      "Epoch 7/15000\n",
      "93484/93484 [==============================] - 26s 277us/step - loss: 0.5436 - acc: 0.9247 - val_loss: 0.6795 - val_acc: 0.8240\n",
      "Epoch 8/15000\n",
      "93484/93484 [==============================] - 26s 275us/step - loss: 0.5343 - acc: 0.9266 - val_loss: 0.5887 - val_acc: 0.8963\n",
      "Epoch 9/15000\n",
      "93484/93484 [==============================] - 26s 278us/step - loss: 0.5237 - acc: 0.9263 - val_loss: 0.5003 - val_acc: 0.9225\n",
      "Epoch 10/15000\n",
      "93484/93484 [==============================] - 26s 280us/step - loss: 0.5184 - acc: 0.9262 - val_loss: 0.5257 - val_acc: 0.9203\n",
      "Epoch 11/15000\n",
      "93484/93484 [==============================] - 26s 279us/step - loss: 0.5127 - acc: 0.9281 - val_loss: 0.7333 - val_acc: 0.8831\n",
      "Epoch 12/15000\n",
      "93484/93484 [==============================] - 26s 278us/step - loss: 0.5094 - acc: 0.9275 - val_loss: 0.5159 - val_acc: 0.9158\n",
      "Epoch 13/15000\n",
      "93484/93484 [==============================] - 26s 279us/step - loss: 0.5015 - acc: 0.9291 - val_loss: 0.8144 - val_acc: 0.8877\n",
      "Epoch 14/15000\n",
      "93484/93484 [==============================] - 27s 284us/step - loss: 0.5051 - acc: 0.9290 - val_loss: 0.8278 - val_acc: 0.8734\n",
      "Epoch 15/15000\n",
      "93484/93484 [==============================] - 26s 282us/step - loss: 0.4996 - acc: 0.9307 - val_loss: 0.5042 - val_acc: 0.9209\n",
      "Epoch 16/15000\n",
      "93484/93484 [==============================] - 28s 299us/step - loss: 0.5057 - acc: 0.9301 - val_loss: 0.9497 - val_acc: 0.8440\n",
      "Epoch 17/15000\n",
      "93484/93484 [==============================] - 27s 291us/step - loss: 0.4943 - acc: 0.9297 - val_loss: 0.8157 - val_acc: 0.8591\n",
      "Epoch 18/15000\n",
      "93484/93484 [==============================] - 28s 298us/step - loss: 0.4948 - acc: 0.9295 - val_loss: 0.5347 - val_acc: 0.9218\n",
      "Epoch 19/15000\n",
      "93484/93484 [==============================] - 27s 286us/step - loss: 0.4888 - acc: 0.9305 - val_loss: 0.5004 - val_acc: 0.9195\n",
      "Epoch 20/15000\n",
      "93484/93484 [==============================] - 27s 290us/step - loss: 0.4888 - acc: 0.9315 - val_loss: 0.5527 - val_acc: 0.9067\n",
      "Epoch 21/15000\n",
      "93484/93484 [==============================] - 27s 292us/step - loss: 0.4889 - acc: 0.9309 - val_loss: 0.5174 - val_acc: 0.9177\n",
      "Epoch 22/15000\n",
      "93484/93484 [==============================] - 27s 289us/step - loss: 0.4831 - acc: 0.9296 - val_loss: 0.5166 - val_acc: 0.9234\n",
      "Epoch 23/15000\n",
      "93484/93484 [==============================] - 27s 288us/step - loss: 0.4823 - acc: 0.9316 - val_loss: 0.5089 - val_acc: 0.9217\n",
      "Epoch 24/15000\n",
      "93484/93484 [==============================] - 28s 299us/step - loss: 0.4865 - acc: 0.9284 - val_loss: 0.5280 - val_acc: 0.9151\n",
      "Epoch 25/15000\n",
      "93300/93484 [============================>.] - ETA: 0s - loss: 0.4851 - acc: 0.9302"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 15000\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "\n",
    "l1v = 0.007\n",
    "l2v = 0.014\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1), \n",
    "                 kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "                 kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1v,l2v)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.40))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(80, activation='relu', kernel_regularizer=regularizers.l1_l2(l1v,l2v), use_bias=True))\n",
    "model.add(Dropout(0.55))\n",
    "model.add(Dense(40, activation='relu', kernel_regularizer=regularizers.l1_l2(l1v,l2v), use_bias=True))\n",
    "model.add(Dropout(0.55))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "current_name = \"KnuckleFinger_Jan_v2_\"\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/\" + current_name + readable_timestamp\n",
    "\n",
    "\n",
    "print(current_name + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/\"+ current_name + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=100, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction, tg_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"CNN_25_02_19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction=np.round(model.predict(x_train))\n",
    "train_prediction=train_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction=np.round(model.predict(x_test))\n",
    "val_prediction=val_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = val_prediction - y_test_one_hot\n",
    "indices = []\n",
    "for i in range(len(val_prediction)):\n",
    "    if np.count_nonzero(delta[i]) > 0:\n",
    "        indices += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist = []\n",
    "for data_point in indices:\n",
    "    print(data_point)\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #plt.subplot(figsize=(6,6))\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_point = indices[0]\n",
    "    data = df_train.Blobs.iloc[data_point]\n",
    "    label = \"Knuckle\" if train_prediction[data_point][0] == 1 else \"Finger\"  \n",
    "    ax.set_title(\"Input method: \" + str(df_train.InputMethod.iloc[data_point]) + \"\\n\" + \"Label as: \"  + label)\n",
    "    #plt.imsave(\"PredictionImages/\" + str(data_point)+\".pdf\", data, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.imsave(\"PredictionImages/{}.png\".format(data_point), data, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    #plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
