{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import telegram\\nfrom keras.callbacks import Callback\\nfrom callbacks import TelegramCallback\\nfrom callbacks.TelegramData import TelegramData\\n\\n\\n# create callback\\nconfig = {\\n    'token': TelegramData.Token,   # paste your bot token\\n    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\\n}\\n\\ntg_callback = TelegramCallback(config)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "test_ids = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "#Create InputMethod Column and fill it with Knuckel / Finger\n",
    "\"\"\"def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "df_train['InputMethod'] = df_train.apply(f, axis=1)\n",
    "df_test['InputMethod'] = df_test.apply(f, axis=1)\"\"\"\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 15, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 8, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               229632    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 328,450\n",
      "Trainable params: 328,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Jan_20190110_111436\n",
      "Train on 154364 samples, validate on 45315 samples\n",
      "Epoch 1/5000\n",
      " 92500/154364 [================>.............] - ETA: 10s - loss: 47.7151 - acc: 0.6386"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "batch_size = 500\n",
    "epochs = 5000\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Robin_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.9, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    optimizer = optimizers.Adam()\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    #init=tf.global_variables_initializer()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "    model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(400, activation=('relu'), use_bias=True))\n",
    "    model.add(Dense(100, activation=('relu'), use_bias=True))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    ####TENSORBOARD\n",
    "    config = \"\"\n",
    "    for layer in model.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "     \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "\n",
    "#set early stopping criteria\n",
    "pat = 5 #this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0, write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "model_checkpoint = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
    "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=500, BATCH_SIZE=200):\n",
    "    model = None\n",
    "    model = cnn_model()\n",
    "    model.summary()\n",
    "    history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, model_checkpoint, tg_callback])\n",
    "    \n",
    "    print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=3\n",
    "epochs=500\n",
    "batch_size=200\n",
    "\n",
    "#save the model history in a list after fitting so that we can plot later\n",
    "model_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    ####TODO\n",
    "    t_x, val_x, t_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    ####END\n",
    "    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracies vs Epochs')\n",
    "plt.plot(model_history[0].history['acc'], label='Training Fold 1')\n",
    "plt.plot(model_history[1].history['acc'], label='Training Fold 2')\n",
    "plt.plot(model_history[2].history['acc'], label='Training Fold 3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"2312.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
