{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1, 2, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17]\n",
    "test_ids = [4, 5, 6, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 15, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 8, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               229632    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 328,450\n",
      "Trainable params: 328,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Robin_20190115_164539\n",
      "Train on 225040 samples, validate on 21799 samples\n",
      "Epoch 1/5000\n",
      "225040/225040 [==============================] - 26s 116us/step - loss: 57.7987 - acc: 0.7148 - val_loss: 1.6199 - val_acc: 0.4953\n",
      "Epoch 2/5000\n",
      "225040/225040 [==============================] - 30s 132us/step - loss: 1.0649 - acc: 0.8626 - val_loss: 0.9821 - val_acc: 0.9038\n",
      "Epoch 3/5000\n",
      "225040/225040 [==============================] - 25s 110us/step - loss: 0.9963 - acc: 0.8851 - val_loss: 0.9668 - val_acc: 0.9055\n",
      "Epoch 4/5000\n",
      "225040/225040 [==============================] - 26s 115us/step - loss: 0.9734 - acc: 0.8994 - val_loss: 0.9306 - val_acc: 0.9194\n",
      "Epoch 5/5000\n",
      "225040/225040 [==============================] - 30s 133us/step - loss: 0.9614 - acc: 0.9050 - val_loss: 1.0055 - val_acc: 0.8896\n",
      "Epoch 6/5000\n",
      "225040/225040 [==============================] - 25s 112us/step - loss: 0.9429 - acc: 0.9128 - val_loss: 0.9197 - val_acc: 0.9193\n",
      "Epoch 7/5000\n",
      "225040/225040 [==============================] - 28s 123us/step - loss: 0.9315 - acc: 0.9167 - val_loss: 0.8927 - val_acc: 0.9292\n",
      "Epoch 8/5000\n",
      "225040/225040 [==============================] - 26s 117us/step - loss: 0.9250 - acc: 0.9184 - val_loss: 1.0791 - val_acc: 0.8560\n",
      "Epoch 9/5000\n",
      "225040/225040 [==============================] - 27s 119us/step - loss: 0.9207 - acc: 0.9195 - val_loss: 0.8934 - val_acc: 0.9338\n",
      "Epoch 10/5000\n",
      "225040/225040 [==============================] - 28s 125us/step - loss: 0.9066 - acc: 0.9256 - val_loss: 1.0630 - val_acc: 0.8849\n",
      "Epoch 11/5000\n",
      "225040/225040 [==============================] - 25s 111us/step - loss: 0.9022 - acc: 0.9256 - val_loss: 0.8988 - val_acc: 0.9136\n",
      "Epoch 12/5000\n",
      "225040/225040 [==============================] - 25s 113us/step - loss: 0.9101 - acc: 0.9219 - val_loss: 0.9311 - val_acc: 0.9173\n",
      "Epoch 13/5000\n",
      "225040/225040 [==============================] - 25s 109us/step - loss: 0.8914 - acc: 0.9286 - val_loss: 0.8641 - val_acc: 0.9372\n",
      "Epoch 14/5000\n",
      "225040/225040 [==============================] - 29s 129us/step - loss: 0.8850 - acc: 0.9302 - val_loss: 0.9556 - val_acc: 0.9222\n",
      "Epoch 15/5000\n",
      "217500/225040 [===========================>..] - ETA: 0s - loss: 0.8796 - acc: 0.9324"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "batch_size = 1500\n",
    "epochs = 5000\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Robin_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Robin_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Robin_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.9, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction, tg_callback])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    optimizer = optimizers.Adam()\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    #init=tf.global_variables_initializer()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    ########## MODEL ARCHITECTURE\n",
    "    ####TENSORBOARD\n",
    "    config = \"\"\n",
    "    for layer in model.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "    # Print summary\n",
    "    model.summary()\n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "    tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Robin_\" + readable_timestamp\n",
    "    print(\"KnuckleFinger_Robin_\" + readable_timestamp)\n",
    "    logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                                write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "    storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Robin_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                patience=10, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.95, \n",
    "                                                min_lr=0.00001)\n",
    "    # compile model for training\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[ storer,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"10_01_19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
