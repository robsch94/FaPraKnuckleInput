{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,   \n",
    "    'model_name': \"JAN_CNN\" # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1, 2, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16]\n",
    "test_ids = [4, 5, 6, 11,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "#df_test = df_test.reset_index()\n",
    "#df_train = df_train.reset_index()\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17,  2, 12, 15,  5,  1, 14, 10, 13,  6, 16,  3,  7,  8,  9, 11,  4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.userID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 15, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label for image 1 is: 1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 15, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 15, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 8, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               229632    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 365,954\n",
      "Trainable params: 365,762\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Jan_20190124_181117\n",
      "Train on 210768 samples, validate on 29742 samples\n",
      "Epoch 1/3000\n",
      "206000/210768 [============================>.] - ETA: 1s - loss: 22.6177 - acc: 0.7864"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "batch_size = 500\n",
    "epochs = 3000\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.55))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=30, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.9, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction, tg_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"CNN_23_01_19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_train, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction=np.round(model.predict(x_train))\n",
    "train_prediction=train_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction=np.round(model.predict(x_test))\n",
    "val_prediction=val_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = val_prediction - y_test_one_hot\n",
    "indices = []\n",
    "for i in range(len(val_prediction)):\n",
    "    if np.count_nonzero(delta[i]) > 0:\n",
    "        indices += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist = []\n",
    "for data_point in indices:\n",
    "    print(data_point)\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #plt.subplot(figsize=(6,6))\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_point = indices[0]\n",
    "    data = df_train.Blobs.iloc[data_point]\n",
    "    label = \"Knuckle\" if train_prediction[data_point][0] == 1 else \"Finger\"  \n",
    "    ax.set_title(\"Input method: \" + str(df_train.InputMethod.iloc[data_point]) + \"\\n\" + \"Label as: \"  + label)\n",
    "    #plt.imsave(\"PredictionImages/\" + str(data_point)+\".pdf\", data, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.imsave(\"PredictionImages/{}.png\".format(data_point), data, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    #plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
