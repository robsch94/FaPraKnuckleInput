{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import telegram\\nfrom keras.callbacks import Callback\\nfrom callbacks import TelegramCallback\\nfrom callbacks.TelegramData import TelegramData\\n\\n\\n# create callback\\nconfig = {\\n    'token': TelegramData.Token,   # paste your bot token\\n    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\\n}\\n\\ntg_callback = TelegramCallback(config)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10]\n",
    "test_ids = [4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'TaskID', 'Version', 'Image', 'InputMethod'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "#Create InputMethod Column and fill it with Knuckel / Finger\n",
    "\"\"\"def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "df_train['InputMethod'] = df_train.apply(f, axis=1)\n",
    "df_test['InputMethod'] = df_test.apply(f, axis=1)\"\"\"\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "epochs = 500\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "#model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.9, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=500,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    optimizer = optimizers.Adam()\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    #init=tf.global_variables_initializer()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "    model.add(Conv2D(120, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(50, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='valid', data_format='channels_last'))\n",
    "    model.add(Dropout(0.10))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(400, activation=('relu'), use_bias=True))\n",
    "    model.add(Dense(100, activation=('relu'), use_bias=True))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    ####TENSORBOARD\n",
    "    config = \"\"\n",
    "    for layer in model.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "     \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph()\n",
    "\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "\n",
    "#set early stopping criteria\n",
    "pat = 5 #this is the number of epochs with no improvment after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0, write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "model_checkpoint = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "\n",
    "def fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=500, BATCH_SIZE=200):\n",
    "    model = None\n",
    "    model = cnn_model()\n",
    "    model.summary()\n",
    "    history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, model_checkpoint, tg_callback])\n",
    "    \n",
    "    print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=3\n",
    "epochs=500\n",
    "batch_size=200\n",
    "\n",
    "#save the model history in a list after fitting so that we can plot later\n",
    "model_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    ####TODO\n",
    "    t_x, val_x, t_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    ####END\n",
    "    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracies vs Epochs')\n",
    "plt.plot(model_history[0].history['acc'], label='Training Fold 1')\n",
    "plt.plot(model_history[1].history['acc'], label='Training Fold 2')\n",
    "plt.plot(model_history[2].history['acc'], label='Training Fold 3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"2312.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
