{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1,2,3, 7, 8, 9, 10,12,13,14]\n",
    "test_ids = [4,5,6,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'TaskID', 'Version', 'Blobs', 'InputMethod'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "#Create InputMethod Column and fill it with Knuckel / Finger\n",
    "\"\"\"def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "df_train['InputMethod'] = df_train.apply(f, axis=1)\n",
    "df_test['InputMethod'] = df_test.apply(f, axis=1)\"\"\"\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 27, 15, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 27, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 8, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               229632    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 328,450\n",
      "Trainable params: 328,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Jan_20190110_114047\n",
      "Train on 268996 samples, validate on 34988 samples\n",
      "Epoch 1/500\n",
      "268996/268996 [==============================] - 62s 229us/step - loss: 17.1609 - acc: 0.7422 - val_loss: 1.0907 - val_acc: 0.8263\n",
      "Epoch 2/500\n",
      "268996/268996 [==============================] - 60s 225us/step - loss: 1.0669 - acc: 0.8432 - val_loss: 0.9537 - val_acc: 0.9077\n",
      "Epoch 3/500\n",
      "268996/268996 [==============================] - 56s 209us/step - loss: 1.0242 - acc: 0.8663 - val_loss: 0.9517 - val_acc: 0.9045\n",
      "Epoch 4/500\n",
      "268996/268996 [==============================] - 57s 213us/step - loss: 1.0011 - acc: 0.8766 - val_loss: 0.9141 - val_acc: 0.9212\n",
      "Epoch 5/500\n",
      "268996/268996 [==============================] - 58s 214us/step - loss: 0.9836 - acc: 0.8828 - val_loss: 0.9914 - val_acc: 0.8951\n",
      "Epoch 6/500\n",
      "268996/268996 [==============================] - 56s 207us/step - loss: 0.9724 - acc: 0.8871 - val_loss: 0.9107 - val_acc: 0.9179\n",
      "Epoch 7/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9613 - acc: 0.8915 - val_loss: 0.8871 - val_acc: 0.9241\n",
      "Epoch 8/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9544 - acc: 0.8941 - val_loss: 0.8818 - val_acc: 0.9229\n",
      "Epoch 9/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9484 - acc: 0.8967 - val_loss: 0.8811 - val_acc: 0.9282\n",
      "Epoch 10/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9450 - acc: 0.8988 - val_loss: 0.8816 - val_acc: 0.9286\n",
      "Epoch 11/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9350 - acc: 0.9058 - val_loss: 0.8753 - val_acc: 0.9328\n",
      "Epoch 12/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9314 - acc: 0.9080 - val_loss: 0.8713 - val_acc: 0.9277\n",
      "Epoch 13/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9294 - acc: 0.9103 - val_loss: 0.9432 - val_acc: 0.9081\n",
      "Epoch 14/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9202 - acc: 0.9141 - val_loss: 0.8883 - val_acc: 0.9267\n",
      "Epoch 15/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9140 - acc: 0.9160 - val_loss: 0.8794 - val_acc: 0.9279\n",
      "Epoch 16/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9084 - acc: 0.9180 - val_loss: 0.8702 - val_acc: 0.9298\n",
      "Epoch 17/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.9081 - acc: 0.9181 - val_loss: 0.8681 - val_acc: 0.9349\n",
      "Epoch 18/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8994 - acc: 0.9212 - val_loss: 0.8701 - val_acc: 0.9283\n",
      "Epoch 19/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8918 - acc: 0.9225 - val_loss: 0.8569 - val_acc: 0.9329\n",
      "Epoch 20/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8887 - acc: 0.9232 - val_loss: 0.8929 - val_acc: 0.9232\n",
      "Epoch 21/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8822 - acc: 0.9247 - val_loss: 0.8548 - val_acc: 0.9343\n",
      "Epoch 22/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8785 - acc: 0.9253 - val_loss: 0.8644 - val_acc: 0.9290\n",
      "Epoch 23/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8745 - acc: 0.9266 - val_loss: 0.8423 - val_acc: 0.9357\n",
      "Epoch 24/500\n",
      "268996/268996 [==============================] - 61s 229us/step - loss: 0.8668 - acc: 0.9279 - val_loss: 0.8602 - val_acc: 0.9279\n",
      "Epoch 25/500\n",
      "268996/268996 [==============================] - 64s 236us/step - loss: 0.8644 - acc: 0.9297 - val_loss: 0.8748 - val_acc: 0.9288\n",
      "Epoch 26/500\n",
      "268996/268996 [==============================] - 66s 245us/step - loss: 0.8617 - acc: 0.9296 - val_loss: 0.8504 - val_acc: 0.9331\n",
      "Epoch 27/500\n",
      "268996/268996 [==============================] - 66s 246us/step - loss: 0.8586 - acc: 0.9302 - val_loss: 0.8439 - val_acc: 0.9359\n",
      "Epoch 28/500\n",
      "268996/268996 [==============================] - 66s 245us/step - loss: 0.8559 - acc: 0.9307 - val_loss: 0.8568 - val_acc: 0.9320\n",
      "Epoch 29/500\n",
      "268996/268996 [==============================] - 66s 245us/step - loss: 0.8537 - acc: 0.9313 - val_loss: 0.8580 - val_acc: 0.9333\n",
      "Epoch 30/500\n",
      "268996/268996 [==============================] - 66s 246us/step - loss: 0.8520 - acc: 0.9316 - val_loss: 0.8357 - val_acc: 0.9352\n",
      "Epoch 31/500\n",
      "268996/268996 [==============================] - 66s 246us/step - loss: 0.8455 - acc: 0.9330 - val_loss: 0.8310 - val_acc: 0.9335\n",
      "Epoch 32/500\n",
      "268996/268996 [==============================] - 66s 246us/step - loss: 0.8456 - acc: 0.9328 - val_loss: 0.8406 - val_acc: 0.9353\n",
      "Epoch 33/500\n",
      "268996/268996 [==============================] - 64s 237us/step - loss: 0.8439 - acc: 0.9332 - val_loss: 0.8368 - val_acc: 0.9351\n",
      "Epoch 34/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8422 - acc: 0.9327 - val_loss: 0.8553 - val_acc: 0.9331\n",
      "Epoch 35/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8391 - acc: 0.9332 - val_loss: 0.8510 - val_acc: 0.9297\n",
      "Epoch 36/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8372 - acc: 0.9343 - val_loss: 0.8319 - val_acc: 0.9319\n",
      "Epoch 37/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8355 - acc: 0.9341 - val_loss: 0.8345 - val_acc: 0.9303\n",
      "Epoch 38/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8297 - acc: 0.9351 - val_loss: 0.8383 - val_acc: 0.9363\n",
      "Epoch 39/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8310 - acc: 0.9351 - val_loss: 0.8603 - val_acc: 0.9313\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8303 - acc: 0.9353 - val_loss: 0.8478 - val_acc: 0.9357\n",
      "Epoch 41/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8297 - acc: 0.9352 - val_loss: 0.8232 - val_acc: 0.9357\n",
      "Epoch 42/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8279 - acc: 0.9362 - val_loss: 0.8114 - val_acc: 0.9367\n",
      "Epoch 43/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8256 - acc: 0.9367 - val_loss: 0.8115 - val_acc: 0.9368\n",
      "Epoch 44/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8249 - acc: 0.9371 - val_loss: 0.8272 - val_acc: 0.9344\n",
      "Epoch 45/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8252 - acc: 0.9373 - val_loss: 0.8589 - val_acc: 0.9289\n",
      "Epoch 46/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8259 - acc: 0.9368 - val_loss: 0.8193 - val_acc: 0.9398\n",
      "Epoch 47/500\n",
      "268996/268996 [==============================] - 61s 227us/step - loss: 0.8215 - acc: 0.9378 - val_loss: 0.8199 - val_acc: 0.9378\n",
      "Epoch 48/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8186 - acc: 0.9383 - val_loss: 0.8276 - val_acc: 0.9332\n",
      "Epoch 49/500\n",
      "268996/268996 [==============================] - 61s 228us/step - loss: 0.8181 - acc: 0.9377 - val_loss: 0.8359 - val_acc: 0.9330\n",
      "Epoch 50/500\n",
      "133500/268996 [=============>................] - ETA: 29s - loss: 0.8163 - acc: 0.9384"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 500\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Jan_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Jan_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Jan_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer,tg_callback, learning_rate_reduction])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"2312.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
