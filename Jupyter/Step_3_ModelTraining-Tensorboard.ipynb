{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [1, 2, 3, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17]\n",
    "test_ids = [4, 5, 6, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "dfAll = pd.read_pickle(\"PklData/df_blobs.pkl\")\n",
    "#df_train = dfAll[(dfAll.userID != 1) | (dfAll.userID != 2)]\n",
    "#df_test = dfAll[(dfAll.userID == 1) | (dfAll.userID == 2)]\n",
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids) & (dfAll.Version == \"Normal\")]\n",
    "\n",
    "df_test = df_test.reset_index()\n",
    "df_train = df_train.reset_index()\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'InputMethod']].copy()\n",
    "df_test2 = df_test[['Blobs', 'InputMethod']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  3,  7, 16,  5,  9, 17, 14,  6, 10,  2,  4, 12,  1, 13,  8, 11])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.userID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack(df_train2.Blobs)\n",
    "x_test = np.vstack(df_test2.Blobs)\n",
    "y_train = df_train2.InputMethod.values\n",
    "y_test = df_test2.InputMethod.values\n",
    "\n",
    "x_train = x_train.reshape(-1, 27, 15, 1)\n",
    "x_test = x_test.reshape(-1, 27, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 15, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = 2\n",
    "y_train_one_hot = utils.to_categorical(df_train2.InputMethod, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.InputMethod, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label for image 1 is: 0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.imshow(x_train[i].reshape(27, 15)) #np.sqrt(784) = 28\n",
    "plt.title(\"Label for image %i is: %s\" % (i, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 15, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 27, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 8, 32)         18464     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 8, 32)         9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 8, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               229632    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 328,450\n",
      "Trainable params: 328,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_Robin_20190111_223837\n",
      "Train on 290344 samples, validate on 45671 samples\n",
      "Epoch 1/400\n",
      "290344/290344 [==============================] - 31s 106us/step - loss: 16.0778 - acc: 0.7754 - val_loss: 1.0341 - val_acc: 0.8793\n",
      "Epoch 2/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 1.0341 - acc: 0.8647 - val_loss: 0.9863 - val_acc: 0.8945\n",
      "Epoch 3/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.9947 - acc: 0.8822 - val_loss: 1.0501 - val_acc: 0.8842\n",
      "Epoch 4/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.9682 - acc: 0.8919 - val_loss: 0.9353 - val_acc: 0.9001\n",
      "Epoch 5/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.9521 - acc: 0.8968 - val_loss: 0.9813 - val_acc: 0.9036\n",
      "Epoch 6/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.9393 - acc: 0.9015 - val_loss: 0.9105 - val_acc: 0.9045\n",
      "Epoch 7/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.9287 - acc: 0.9044 - val_loss: 0.9550 - val_acc: 0.9091\n",
      "Epoch 8/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.9206 - acc: 0.9080 - val_loss: 0.9111 - val_acc: 0.9095\n",
      "Epoch 9/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.9151 - acc: 0.9098 - val_loss: 0.8970 - val_acc: 0.9210\n",
      "Epoch 10/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.9116 - acc: 0.9120 - val_loss: 0.9026 - val_acc: 0.9247\n",
      "Epoch 11/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.9104 - acc: 0.9138 - val_loss: 0.9259 - val_acc: 0.9154\n",
      "Epoch 12/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.9072 - acc: 0.9155 - val_loss: 0.9177 - val_acc: 0.9195\n",
      "Epoch 13/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.9054 - acc: 0.9165 - val_loss: 0.9078 - val_acc: 0.9212\n",
      "Epoch 14/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.8997 - acc: 0.9184 - val_loss: 0.9117 - val_acc: 0.9205\n",
      "Epoch 15/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8970 - acc: 0.9190 - val_loss: 0.9098 - val_acc: 0.9202\n",
      "Epoch 16/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8911 - acc: 0.9206 - val_loss: 0.8925 - val_acc: 0.9228\n",
      "Epoch 17/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.8867 - acc: 0.9219 - val_loss: 0.8964 - val_acc: 0.9211\n",
      "Epoch 18/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8798 - acc: 0.9240 - val_loss: 0.9596 - val_acc: 0.9147\n",
      "Epoch 19/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8755 - acc: 0.9250 - val_loss: 0.9109 - val_acc: 0.9177\n",
      "Epoch 20/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.8704 - acc: 0.9265 - val_loss: 0.8806 - val_acc: 0.9246\n",
      "Epoch 21/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8623 - acc: 0.9287 - val_loss: 0.8962 - val_acc: 0.9141\n",
      "Epoch 22/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8593 - acc: 0.9289 - val_loss: 0.9394 - val_acc: 0.9152\n",
      "Epoch 23/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8544 - acc: 0.9299 - val_loss: 0.8685 - val_acc: 0.9228\n",
      "Epoch 24/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8507 - acc: 0.9309 - val_loss: 0.9019 - val_acc: 0.9190\n",
      "Epoch 25/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8471 - acc: 0.9319 - val_loss: 0.8634 - val_acc: 0.9204\n",
      "Epoch 26/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8438 - acc: 0.9324 - val_loss: 0.8596 - val_acc: 0.9194\n",
      "Epoch 27/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8408 - acc: 0.9331 - val_loss: 0.9066 - val_acc: 0.9177\n",
      "Epoch 28/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8367 - acc: 0.9332 - val_loss: 0.8752 - val_acc: 0.9198\n",
      "Epoch 29/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8328 - acc: 0.9343 - val_loss: 0.8608 - val_acc: 0.9220\n",
      "Epoch 30/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8305 - acc: 0.9347 - val_loss: 0.8855 - val_acc: 0.9217\n",
      "Epoch 31/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.8289 - acc: 0.9354 - val_loss: 0.8906 - val_acc: 0.9166\n",
      "Epoch 32/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8258 - acc: 0.9357 - val_loss: 0.9000 - val_acc: 0.9204\n",
      "Epoch 33/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8243 - acc: 0.9365 - val_loss: 0.8852 - val_acc: 0.9152\n",
      "Epoch 34/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.8237 - acc: 0.9367 - val_loss: 0.9255 - val_acc: 0.9066\n",
      "Epoch 35/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8195 - acc: 0.9373 - val_loss: 0.8666 - val_acc: 0.9216\n",
      "Epoch 36/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.8199 - acc: 0.9376 - val_loss: 0.8839 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "Epoch 37/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.7553 - acc: 0.9387 - val_loss: 0.8181 - val_acc: 0.9155\n",
      "Epoch 38/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7532 - acc: 0.9392 - val_loss: 0.8165 - val_acc: 0.9214\n",
      "Epoch 39/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7548 - acc: 0.9393 - val_loss: 0.8118 - val_acc: 0.9178\n",
      "Epoch 40/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7515 - acc: 0.9399 - val_loss: 0.7919 - val_acc: 0.9205\n",
      "Epoch 41/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7524 - acc: 0.9399 - val_loss: 0.8011 - val_acc: 0.9194\n",
      "Epoch 42/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7495 - acc: 0.9402 - val_loss: 0.7892 - val_acc: 0.9244\n",
      "Epoch 43/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7500 - acc: 0.9407 - val_loss: 0.8419 - val_acc: 0.9137\n",
      "Epoch 44/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7533 - acc: 0.9403 - val_loss: 0.7957 - val_acc: 0.9199\n",
      "Epoch 45/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7490 - acc: 0.9415 - val_loss: 0.8070 - val_acc: 0.9229\n",
      "Epoch 46/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7497 - acc: 0.9416 - val_loss: 0.7935 - val_acc: 0.9192\n",
      "Epoch 47/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7471 - acc: 0.9416 - val_loss: 0.8037 - val_acc: 0.9212\n",
      "Epoch 48/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7470 - acc: 0.9421 - val_loss: 0.8028 - val_acc: 0.9223\n",
      "Epoch 49/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7493 - acc: 0.9422 - val_loss: 0.8018 - val_acc: 0.9159\n",
      "Epoch 50/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7470 - acc: 0.9431 - val_loss: 0.8314 - val_acc: 0.9226\n",
      "Epoch 51/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7489 - acc: 0.9427 - val_loss: 0.8393 - val_acc: 0.9200\n",
      "Epoch 52/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.7466 - acc: 0.9431 - val_loss: 0.8296 - val_acc: 0.9222\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "Epoch 53/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6893 - acc: 0.9435 - val_loss: 0.7755 - val_acc: 0.9181\n",
      "Epoch 54/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6834 - acc: 0.9445 - val_loss: 0.7857 - val_acc: 0.9194\n",
      "Epoch 55/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6887 - acc: 0.9444 - val_loss: 0.7671 - val_acc: 0.9193\n",
      "Epoch 56/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6913 - acc: 0.9449 - val_loss: 0.7709 - val_acc: 0.9189\n",
      "Epoch 57/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6896 - acc: 0.9444 - val_loss: 0.7686 - val_acc: 0.9163\n",
      "Epoch 58/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6872 - acc: 0.9451 - val_loss: 0.7330 - val_acc: 0.9192\n",
      "Epoch 59/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6928 - acc: 0.9452 - val_loss: 0.7796 - val_acc: 0.9180\n",
      "Epoch 60/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6911 - acc: 0.9455 - val_loss: 0.8044 - val_acc: 0.9182\n",
      "Epoch 61/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6849 - acc: 0.9453 - val_loss: 0.7433 - val_acc: 0.9224\n",
      "Epoch 62/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6822 - acc: 0.9456 - val_loss: 0.7447 - val_acc: 0.9223\n",
      "Epoch 63/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6907 - acc: 0.9462 - val_loss: 0.7485 - val_acc: 0.9191\n",
      "Epoch 64/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6880 - acc: 0.9458 - val_loss: 0.7532 - val_acc: 0.9199\n",
      "Epoch 65/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6857 - acc: 0.9457 - val_loss: 0.7742 - val_acc: 0.9188\n",
      "Epoch 66/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6854 - acc: 0.9461 - val_loss: 0.7690 - val_acc: 0.9171\n",
      "Epoch 67/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6871 - acc: 0.9462 - val_loss: 0.7583 - val_acc: 0.9176\n",
      "Epoch 68/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6876 - acc: 0.9467 - val_loss: 0.7736 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "Epoch 69/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6324 - acc: 0.9479 - val_loss: 0.7142 - val_acc: 0.9205\n",
      "Epoch 70/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6315 - acc: 0.9478 - val_loss: 0.7250 - val_acc: 0.9197\n",
      "Epoch 71/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6310 - acc: 0.9475 - val_loss: 0.7037 - val_acc: 0.9220\n",
      "Epoch 72/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6302 - acc: 0.9479 - val_loss: 0.7479 - val_acc: 0.9210\n",
      "Epoch 73/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6293 - acc: 0.9486 - val_loss: 0.6997 - val_acc: 0.9139\n",
      "Epoch 74/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6271 - acc: 0.9485 - val_loss: 0.7320 - val_acc: 0.9210\n",
      "Epoch 75/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6307 - acc: 0.9480 - val_loss: 0.7301 - val_acc: 0.9191\n",
      "Epoch 76/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6299 - acc: 0.9486 - val_loss: 0.6987 - val_acc: 0.9208\n",
      "Epoch 77/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6339 - acc: 0.9484 - val_loss: 0.7045 - val_acc: 0.9203\n",
      "Epoch 78/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6293 - acc: 0.9484 - val_loss: 0.7408 - val_acc: 0.9190\n",
      "Epoch 79/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6273 - acc: 0.9488 - val_loss: 0.7532 - val_acc: 0.9152\n",
      "Epoch 80/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6319 - acc: 0.9491 - val_loss: 0.7031 - val_acc: 0.9216\n",
      "Epoch 81/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6282 - acc: 0.9489 - val_loss: 0.7193 - val_acc: 0.9216\n",
      "Epoch 82/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6255 - acc: 0.9492 - val_loss: 0.7215 - val_acc: 0.9208\n",
      "Epoch 83/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6295 - acc: 0.9485 - val_loss: 0.7082 - val_acc: 0.9217\n",
      "Epoch 84/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6310 - acc: 0.9485 - val_loss: 0.7254 - val_acc: 0.9219\n",
      "Epoch 85/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6299 - acc: 0.9498 - val_loss: 0.7097 - val_acc: 0.9232\n",
      "Epoch 86/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.6379 - acc: 0.9490 - val_loss: 0.7455 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "Epoch 87/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5779 - acc: 0.9496 - val_loss: 0.6666 - val_acc: 0.9203\n",
      "Epoch 88/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5806 - acc: 0.9500 - val_loss: 0.6963 - val_acc: 0.9200\n",
      "Epoch 89/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5816 - acc: 0.9498 - val_loss: 0.6709 - val_acc: 0.9206\n",
      "Epoch 90/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5795 - acc: 0.9502 - val_loss: 0.6796 - val_acc: 0.9201\n",
      "Epoch 91/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5785 - acc: 0.9505 - val_loss: 0.6463 - val_acc: 0.9255\n",
      "Epoch 92/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5804 - acc: 0.9505 - val_loss: 0.6768 - val_acc: 0.9209\n",
      "Epoch 93/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5762 - acc: 0.9508 - val_loss: 0.6635 - val_acc: 0.9192\n",
      "Epoch 94/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5771 - acc: 0.9507 - val_loss: 0.6634 - val_acc: 0.9226\n",
      "Epoch 95/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5822 - acc: 0.9508 - val_loss: 0.6703 - val_acc: 0.9200\n",
      "Epoch 96/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5794 - acc: 0.9511 - val_loss: 0.6848 - val_acc: 0.9184\n",
      "Epoch 97/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5821 - acc: 0.9512 - val_loss: 0.6609 - val_acc: 0.9182\n",
      "Epoch 98/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5796 - acc: 0.9511 - val_loss: 0.6542 - val_acc: 0.9207\n",
      "Epoch 99/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5812 - acc: 0.9509 - val_loss: 0.7303 - val_acc: 0.9194\n",
      "Epoch 100/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5833 - acc: 0.9511 - val_loss: 0.6923 - val_acc: 0.9221\n",
      "Epoch 101/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5859 - acc: 0.9510 - val_loss: 0.6744 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "Epoch 102/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5349 - acc: 0.9517 - val_loss: 0.6450 - val_acc: 0.9217\n",
      "Epoch 103/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5346 - acc: 0.9517 - val_loss: 0.6278 - val_acc: 0.9219\n",
      "Epoch 104/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5361 - acc: 0.9521 - val_loss: 0.6182 - val_acc: 0.9229\n",
      "Epoch 105/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5361 - acc: 0.9525 - val_loss: 0.6677 - val_acc: 0.9207\n",
      "Epoch 106/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5371 - acc: 0.9521 - val_loss: 0.6354 - val_acc: 0.9213\n",
      "Epoch 107/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5393 - acc: 0.9512 - val_loss: 0.6229 - val_acc: 0.9201\n",
      "Epoch 108/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5343 - acc: 0.9528 - val_loss: 0.6524 - val_acc: 0.9216\n",
      "Epoch 109/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5317 - acc: 0.9528 - val_loss: 0.6114 - val_acc: 0.9239\n",
      "Epoch 110/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5328 - acc: 0.9531 - val_loss: 0.6493 - val_acc: 0.9199\n",
      "Epoch 111/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5380 - acc: 0.9522 - val_loss: 0.6253 - val_acc: 0.9248\n",
      "Epoch 112/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5331 - acc: 0.9527 - val_loss: 0.6432 - val_acc: 0.9219\n",
      "Epoch 113/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5349 - acc: 0.9530 - val_loss: 0.6730 - val_acc: 0.9201\n",
      "Epoch 114/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5364 - acc: 0.9520 - val_loss: 0.6290 - val_acc: 0.9219\n",
      "Epoch 115/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5297 - acc: 0.9533 - val_loss: 0.6153 - val_acc: 0.9238\n",
      "Epoch 116/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5344 - acc: 0.9527 - val_loss: 0.6579 - val_acc: 0.9194\n",
      "Epoch 117/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5403 - acc: 0.9530 - val_loss: 0.6523 - val_acc: 0.9191\n",
      "Epoch 118/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5372 - acc: 0.9526 - val_loss: 0.6269 - val_acc: 0.9207\n",
      "Epoch 119/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.5310 - acc: 0.9530 - val_loss: 0.6270 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "Epoch 120/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4931 - acc: 0.9534 - val_loss: 0.5726 - val_acc: 0.9221\n",
      "Epoch 121/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4943 - acc: 0.9531 - val_loss: 0.5879 - val_acc: 0.9191\n",
      "Epoch 122/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4935 - acc: 0.9537 - val_loss: 0.5897 - val_acc: 0.9196\n",
      "Epoch 123/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4948 - acc: 0.9541 - val_loss: 0.6045 - val_acc: 0.9169\n",
      "Epoch 124/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4908 - acc: 0.9543 - val_loss: 0.6243 - val_acc: 0.9174\n",
      "Epoch 125/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4943 - acc: 0.9535 - val_loss: 0.5978 - val_acc: 0.9243\n",
      "Epoch 126/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4941 - acc: 0.9537 - val_loss: 0.6371 - val_acc: 0.9200\n",
      "Epoch 127/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4991 - acc: 0.9538 - val_loss: 0.5770 - val_acc: 0.9224\n",
      "Epoch 128/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4972 - acc: 0.9541 - val_loss: 0.6204 - val_acc: 0.9199\n",
      "Epoch 129/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4936 - acc: 0.9543 - val_loss: 0.5804 - val_acc: 0.9223\n",
      "Epoch 130/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4908 - acc: 0.9544 - val_loss: 0.6320 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "Epoch 131/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4557 - acc: 0.9552 - val_loss: 0.5531 - val_acc: 0.9221\n",
      "Epoch 132/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4548 - acc: 0.9551 - val_loss: 0.5728 - val_acc: 0.9181\n",
      "Epoch 133/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4546 - acc: 0.9551 - val_loss: 0.5536 - val_acc: 0.9228\n",
      "Epoch 134/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4561 - acc: 0.9553 - val_loss: 0.5879 - val_acc: 0.9207\n",
      "Epoch 135/400\n",
      "290344/290344 [==============================] - 28s 96us/step - loss: 0.4607 - acc: 0.9551 - val_loss: 0.5516 - val_acc: 0.9208\n",
      "Epoch 136/400\n",
      "290344/290344 [==============================] - 27s 92us/step - loss: 0.4596 - acc: 0.9548 - val_loss: 0.5338 - val_acc: 0.9239\n",
      "Epoch 137/400\n",
      "290344/290344 [==============================] - 27s 92us/step - loss: 0.4581 - acc: 0.9556 - val_loss: 0.5695 - val_acc: 0.9188\n",
      "Epoch 138/400\n",
      "290344/290344 [==============================] - 27s 91us/step - loss: 0.4605 - acc: 0.9547 - val_loss: 0.5846 - val_acc: 0.9231\n",
      "Epoch 139/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4575 - acc: 0.9552 - val_loss: 0.5755 - val_acc: 0.9214\n",
      "Epoch 140/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4600 - acc: 0.9552 - val_loss: 0.5962 - val_acc: 0.9189\n",
      "Epoch 141/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4542 - acc: 0.9561 - val_loss: 0.5524 - val_acc: 0.9214\n",
      "Epoch 142/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4578 - acc: 0.9555 - val_loss: 0.5577 - val_acc: 0.9208\n",
      "Epoch 143/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4556 - acc: 0.9558 - val_loss: 0.5879 - val_acc: 0.9215\n",
      "Epoch 144/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4541 - acc: 0.9557 - val_loss: 0.5657 - val_acc: 0.9196\n",
      "Epoch 145/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4580 - acc: 0.9561 - val_loss: 0.5663 - val_acc: 0.9194\n",
      "Epoch 146/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4562 - acc: 0.9559 - val_loss: 0.5776 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "Epoch 147/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4235 - acc: 0.9561 - val_loss: 0.5513 - val_acc: 0.9196\n",
      "Epoch 148/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4227 - acc: 0.9570 - val_loss: 0.5416 - val_acc: 0.9208\n",
      "Epoch 149/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4215 - acc: 0.9565 - val_loss: 0.5243 - val_acc: 0.9229\n",
      "Epoch 150/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4219 - acc: 0.9568 - val_loss: 0.5405 - val_acc: 0.9224\n",
      "Epoch 151/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4213 - acc: 0.9568 - val_loss: 0.5527 - val_acc: 0.9218\n",
      "Epoch 152/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4237 - acc: 0.9566 - val_loss: 0.5541 - val_acc: 0.9204\n",
      "Epoch 153/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4248 - acc: 0.9565 - val_loss: 0.5264 - val_acc: 0.9223\n",
      "Epoch 154/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4250 - acc: 0.9566 - val_loss: 0.5563 - val_acc: 0.9215\n",
      "Epoch 155/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.4242 - acc: 0.9565 - val_loss: 0.5402 - val_acc: 0.9224\n",
      "Epoch 156/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4225 - acc: 0.9566 - val_loss: 0.5371 - val_acc: 0.9222\n",
      "Epoch 157/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.4214 - acc: 0.9570 - val_loss: 0.5592 - val_acc: 0.9194\n",
      "Epoch 158/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.4224 - acc: 0.9566 - val_loss: 0.5771 - val_acc: 0.9212\n",
      "Epoch 159/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.4223 - acc: 0.9563 - val_loss: 0.5294 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "Epoch 160/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3922 - acc: 0.9570 - val_loss: 0.5241 - val_acc: 0.9203\n",
      "Epoch 161/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3921 - acc: 0.9574 - val_loss: 0.5023 - val_acc: 0.9229\n",
      "Epoch 162/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3929 - acc: 0.9572 - val_loss: 0.5296 - val_acc: 0.9190\n",
      "Epoch 163/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3916 - acc: 0.9577 - val_loss: 0.4972 - val_acc: 0.9203\n",
      "Epoch 164/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3924 - acc: 0.9576 - val_loss: 0.5324 - val_acc: 0.9231\n",
      "Epoch 165/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3934 - acc: 0.9573 - val_loss: 0.5514 - val_acc: 0.9183\n",
      "Epoch 166/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3975 - acc: 0.9574 - val_loss: 0.5045 - val_acc: 0.9232\n",
      "Epoch 167/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3935 - acc: 0.9575 - val_loss: 0.5196 - val_acc: 0.9221\n",
      "Epoch 168/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3944 - acc: 0.9577 - val_loss: 0.5225 - val_acc: 0.9209\n",
      "Epoch 169/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3962 - acc: 0.9578 - val_loss: 0.4979 - val_acc: 0.9223\n",
      "Epoch 170/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3905 - acc: 0.9579 - val_loss: 0.5405 - val_acc: 0.9209\n",
      "Epoch 171/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3952 - acc: 0.9578 - val_loss: 0.5122 - val_acc: 0.9232\n",
      "Epoch 172/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3939 - acc: 0.9578 - val_loss: 0.5077 - val_acc: 0.9247\n",
      "Epoch 173/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3920 - acc: 0.9576 - val_loss: 0.5225 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "Epoch 174/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3641 - acc: 0.9587 - val_loss: 0.5121 - val_acc: 0.9231\n",
      "Epoch 175/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3645 - acc: 0.9581 - val_loss: 0.4803 - val_acc: 0.9191\n",
      "Epoch 176/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3671 - acc: 0.9583 - val_loss: 0.4824 - val_acc: 0.9218\n",
      "Epoch 177/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3648 - acc: 0.9590 - val_loss: 0.5057 - val_acc: 0.9200\n",
      "Epoch 178/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3677 - acc: 0.9581 - val_loss: 0.4946 - val_acc: 0.9207\n",
      "Epoch 179/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3675 - acc: 0.9584 - val_loss: 0.4974 - val_acc: 0.9238\n",
      "Epoch 180/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3654 - acc: 0.9592 - val_loss: 0.5003 - val_acc: 0.9201\n",
      "Epoch 181/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3659 - acc: 0.9591 - val_loss: 0.5236 - val_acc: 0.9216\n",
      "Epoch 182/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3683 - acc: 0.9588 - val_loss: 0.5019 - val_acc: 0.9212\n",
      "Epoch 183/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3676 - acc: 0.9587 - val_loss: 0.4931 - val_acc: 0.9194\n",
      "Epoch 184/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3663 - acc: 0.9591 - val_loss: 0.5238 - val_acc: 0.9226\n",
      "Epoch 185/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3662 - acc: 0.9592 - val_loss: 0.4943 - val_acc: 0.9215\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
      "Epoch 186/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3391 - acc: 0.9589 - val_loss: 0.4782 - val_acc: 0.9214\n",
      "Epoch 187/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3404 - acc: 0.9592 - val_loss: 0.4683 - val_acc: 0.9212\n",
      "Epoch 188/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3401 - acc: 0.9591 - val_loss: 0.4678 - val_acc: 0.9222\n",
      "Epoch 189/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3394 - acc: 0.9592 - val_loss: 0.4603 - val_acc: 0.9205\n",
      "Epoch 190/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3409 - acc: 0.9595 - val_loss: 0.4684 - val_acc: 0.9228\n",
      "Epoch 191/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3401 - acc: 0.9593 - val_loss: 0.4558 - val_acc: 0.9216\n",
      "Epoch 192/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3398 - acc: 0.9594 - val_loss: 0.4598 - val_acc: 0.9206\n",
      "Epoch 193/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3405 - acc: 0.9596 - val_loss: 0.4749 - val_acc: 0.9222\n",
      "Epoch 194/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3408 - acc: 0.9586 - val_loss: 0.4610 - val_acc: 0.9198\n",
      "Epoch 195/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3397 - acc: 0.9595 - val_loss: 0.4728 - val_acc: 0.9205\n",
      "Epoch 196/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3385 - acc: 0.9595 - val_loss: 0.4612 - val_acc: 0.9184\n",
      "Epoch 197/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3439 - acc: 0.9595 - val_loss: 0.4946 - val_acc: 0.9194\n",
      "Epoch 198/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3408 - acc: 0.9591 - val_loss: 0.4819 - val_acc: 0.9220\n",
      "Epoch 199/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3401 - acc: 0.9597 - val_loss: 0.5082 - val_acc: 0.9203\n",
      "Epoch 200/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3412 - acc: 0.9596 - val_loss: 0.4350 - val_acc: 0.9242\n",
      "Epoch 201/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3420 - acc: 0.9596 - val_loss: 0.4631 - val_acc: 0.9219\n",
      "Epoch 202/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3432 - acc: 0.9598 - val_loss: 0.4947 - val_acc: 0.9185\n",
      "Epoch 203/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3433 - acc: 0.9597 - val_loss: 0.4523 - val_acc: 0.9213\n",
      "Epoch 204/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3436 - acc: 0.9594 - val_loss: 0.4726 - val_acc: 0.9217\n",
      "Epoch 205/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3411 - acc: 0.9600 - val_loss: 0.4636 - val_acc: 0.9235\n",
      "Epoch 206/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3431 - acc: 0.9598 - val_loss: 0.4854 - val_acc: 0.9192\n",
      "Epoch 207/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3412 - acc: 0.9602 - val_loss: 0.4696 - val_acc: 0.9222\n",
      "Epoch 208/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3417 - acc: 0.9598 - val_loss: 0.4772 - val_acc: 0.9218\n",
      "Epoch 209/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3405 - acc: 0.9601 - val_loss: 0.5056 - val_acc: 0.9191\n",
      "Epoch 210/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3416 - acc: 0.9599 - val_loss: 0.4897 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
      "Epoch 211/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3202 - acc: 0.9599 - val_loss: 0.4775 - val_acc: 0.9206\n",
      "Epoch 212/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3179 - acc: 0.9603 - val_loss: 0.4719 - val_acc: 0.9209\n",
      "Epoch 213/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3206 - acc: 0.9603 - val_loss: 0.4399 - val_acc: 0.9221\n",
      "Epoch 214/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3162 - acc: 0.9604 - val_loss: 0.4671 - val_acc: 0.9203\n",
      "Epoch 215/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3213 - acc: 0.9605 - val_loss: 0.4818 - val_acc: 0.9200\n",
      "Epoch 216/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3214 - acc: 0.9603 - val_loss: 0.4490 - val_acc: 0.9227\n",
      "Epoch 217/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3178 - acc: 0.9606 - val_loss: 0.4352 - val_acc: 0.9229\n",
      "Epoch 218/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.3181 - acc: 0.9610 - val_loss: 0.4589 - val_acc: 0.9206\n",
      "Epoch 219/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.3196 - acc: 0.9599 - val_loss: 0.4488 - val_acc: 0.9200\n",
      "Epoch 220/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.3198 - acc: 0.9610 - val_loss: 0.4825 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
      "Epoch 221/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2992 - acc: 0.9608 - val_loss: 0.4364 - val_acc: 0.9216\n",
      "Epoch 222/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2996 - acc: 0.9607 - val_loss: 0.4372 - val_acc: 0.9231\n",
      "Epoch 223/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2964 - acc: 0.9612 - val_loss: 0.4218 - val_acc: 0.9217\n",
      "Epoch 224/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2971 - acc: 0.9612 - val_loss: 0.4094 - val_acc: 0.9231\n",
      "Epoch 225/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2979 - acc: 0.9609 - val_loss: 0.4109 - val_acc: 0.9204\n",
      "Epoch 226/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2985 - acc: 0.9609 - val_loss: 0.4236 - val_acc: 0.9193\n",
      "Epoch 227/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2976 - acc: 0.9615 - val_loss: 0.4238 - val_acc: 0.9201\n",
      "Epoch 228/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2994 - acc: 0.9611 - val_loss: 0.4393 - val_acc: 0.9207\n",
      "Epoch 229/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2974 - acc: 0.9613 - val_loss: 0.4648 - val_acc: 0.9194\n",
      "Epoch 230/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2973 - acc: 0.9611 - val_loss: 0.4755 - val_acc: 0.9181\n",
      "Epoch 231/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2983 - acc: 0.9610 - val_loss: 0.4624 - val_acc: 0.9206\n",
      "Epoch 232/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2975 - acc: 0.9617 - val_loss: 0.4330 - val_acc: 0.9201\n",
      "Epoch 233/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2977 - acc: 0.9610 - val_loss: 0.4273 - val_acc: 0.9200\n",
      "Epoch 234/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2981 - acc: 0.9610 - val_loss: 0.4420 - val_acc: 0.9208\n",
      "\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
      "Epoch 235/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2795 - acc: 0.9613 - val_loss: 0.3919 - val_acc: 0.9224\n",
      "Epoch 236/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2804 - acc: 0.9618 - val_loss: 0.4272 - val_acc: 0.9205\n",
      "Epoch 237/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2788 - acc: 0.9619 - val_loss: 0.4425 - val_acc: 0.9227\n",
      "Epoch 238/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2791 - acc: 0.9615 - val_loss: 0.4442 - val_acc: 0.9194\n",
      "Epoch 239/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2799 - acc: 0.9617 - val_loss: 0.4276 - val_acc: 0.9200\n",
      "Epoch 240/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2779 - acc: 0.9612 - val_loss: 0.4416 - val_acc: 0.9187\n",
      "Epoch 241/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2778 - acc: 0.9622 - val_loss: 0.4435 - val_acc: 0.9215\n",
      "Epoch 242/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2797 - acc: 0.9613 - val_loss: 0.4390 - val_acc: 0.9199\n",
      "Epoch 243/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2809 - acc: 0.9619 - val_loss: 0.4354 - val_acc: 0.9210\n",
      "Epoch 244/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2789 - acc: 0.9620 - val_loss: 0.4300 - val_acc: 0.9198\n",
      "Epoch 245/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2790 - acc: 0.9614 - val_loss: 0.3923 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 0.00020589114428730683.\n",
      "Epoch 246/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2601 - acc: 0.9621 - val_loss: 0.4295 - val_acc: 0.9198\n",
      "Epoch 247/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2626 - acc: 0.9623 - val_loss: 0.4128 - val_acc: 0.9204\n",
      "Epoch 248/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2627 - acc: 0.9623 - val_loss: 0.3975 - val_acc: 0.9213\n",
      "Epoch 249/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2645 - acc: 0.9619 - val_loss: 0.3875 - val_acc: 0.9234\n",
      "Epoch 250/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2628 - acc: 0.9619 - val_loss: 0.4262 - val_acc: 0.9209\n",
      "Epoch 251/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2622 - acc: 0.9623 - val_loss: 0.4160 - val_acc: 0.9200\n",
      "Epoch 252/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2632 - acc: 0.9616 - val_loss: 0.4297 - val_acc: 0.9226\n",
      "Epoch 253/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2626 - acc: 0.9625 - val_loss: 0.4381 - val_acc: 0.9208\n",
      "Epoch 254/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2636 - acc: 0.9618 - val_loss: 0.3854 - val_acc: 0.9218\n",
      "Epoch 255/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2610 - acc: 0.9622 - val_loss: 0.4302 - val_acc: 0.9181\n",
      "Epoch 256/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2613 - acc: 0.9622 - val_loss: 0.4009 - val_acc: 0.9217\n",
      "Epoch 257/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2622 - acc: 0.9621 - val_loss: 0.4023 - val_acc: 0.9211\n",
      "Epoch 258/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2610 - acc: 0.9622 - val_loss: 0.4173 - val_acc: 0.9195\n",
      "Epoch 259/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2598 - acc: 0.9629 - val_loss: 0.4091 - val_acc: 0.9223\n",
      "Epoch 260/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2608 - acc: 0.9621 - val_loss: 0.3968 - val_acc: 0.9195\n",
      "Epoch 261/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2603 - acc: 0.9623 - val_loss: 0.4193 - val_acc: 0.9221\n",
      "Epoch 262/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2621 - acc: 0.9619 - val_loss: 0.3917 - val_acc: 0.9212\n",
      "Epoch 263/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2610 - acc: 0.9627 - val_loss: 0.3992 - val_acc: 0.9226\n",
      "Epoch 264/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2620 - acc: 0.9616 - val_loss: 0.4165 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 0.00018530203378759326.\n",
      "Epoch 265/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2484 - acc: 0.9624 - val_loss: 0.4442 - val_acc: 0.9195\n",
      "Epoch 266/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2463 - acc: 0.9631 - val_loss: 0.3627 - val_acc: 0.9213\n",
      "Epoch 267/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2457 - acc: 0.9624 - val_loss: 0.3827 - val_acc: 0.9215\n",
      "Epoch 268/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2466 - acc: 0.9626 - val_loss: 0.3845 - val_acc: 0.9208\n",
      "Epoch 269/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2453 - acc: 0.9636 - val_loss: 0.3719 - val_acc: 0.9216\n",
      "Epoch 270/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2467 - acc: 0.9621 - val_loss: 0.3848 - val_acc: 0.9209\n",
      "Epoch 271/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2473 - acc: 0.9626 - val_loss: 0.4114 - val_acc: 0.9203\n",
      "Epoch 272/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2472 - acc: 0.9625 - val_loss: 0.3910 - val_acc: 0.9196\n",
      "Epoch 273/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2462 - acc: 0.9626 - val_loss: 0.3968 - val_acc: 0.9238\n",
      "Epoch 274/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2467 - acc: 0.9628 - val_loss: 0.3953 - val_acc: 0.9219\n",
      "Epoch 275/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2454 - acc: 0.9627 - val_loss: 0.3779 - val_acc: 0.9233\n",
      "Epoch 276/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2449 - acc: 0.9630 - val_loss: 0.4164 - val_acc: 0.9197\n",
      "\n",
      "Epoch 00276: ReduceLROnPlateau reducing learning rate to 0.00016677183302817866.\n",
      "Epoch 277/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2318 - acc: 0.9634 - val_loss: 0.3952 - val_acc: 0.9194\n",
      "Epoch 278/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2333 - acc: 0.9627 - val_loss: 0.3942 - val_acc: 0.9192\n",
      "Epoch 279/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2341 - acc: 0.9630 - val_loss: 0.3831 - val_acc: 0.9210\n",
      "Epoch 280/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2326 - acc: 0.9631 - val_loss: 0.3837 - val_acc: 0.9214\n",
      "Epoch 281/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2324 - acc: 0.9628 - val_loss: 0.3826 - val_acc: 0.9192\n",
      "Epoch 282/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2334 - acc: 0.9632 - val_loss: 0.3940 - val_acc: 0.9220\n",
      "Epoch 283/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2314 - acc: 0.9631 - val_loss: 0.3749 - val_acc: 0.9199\n",
      "Epoch 284/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2317 - acc: 0.9634 - val_loss: 0.3769 - val_acc: 0.9215\n",
      "Epoch 285/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2312 - acc: 0.9628 - val_loss: 0.3912 - val_acc: 0.9200\n",
      "Epoch 286/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2325 - acc: 0.9632 - val_loss: 0.3827 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00286: ReduceLROnPlateau reducing learning rate to 0.00015009464841568844.\n",
      "Epoch 287/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2205 - acc: 0.9633 - val_loss: 0.3805 - val_acc: 0.9234\n",
      "Epoch 288/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2191 - acc: 0.9638 - val_loss: 0.3829 - val_acc: 0.9210\n",
      "Epoch 289/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2203 - acc: 0.9635 - val_loss: 0.3533 - val_acc: 0.9225\n",
      "Epoch 290/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2194 - acc: 0.9638 - val_loss: 0.3740 - val_acc: 0.9211\n",
      "Epoch 291/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2198 - acc: 0.9638 - val_loss: 0.3683 - val_acc: 0.9228\n",
      "Epoch 292/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2205 - acc: 0.9637 - val_loss: 0.3817 - val_acc: 0.9210\n",
      "Epoch 293/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2213 - acc: 0.9637 - val_loss: 0.3799 - val_acc: 0.9205\n",
      "Epoch 294/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2208 - acc: 0.9631 - val_loss: 0.3532 - val_acc: 0.9203\n",
      "Epoch 295/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2191 - acc: 0.9638 - val_loss: 0.3783 - val_acc: 0.9201\n",
      "Epoch 296/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2204 - acc: 0.9631 - val_loss: 0.3702 - val_acc: 0.9213\n",
      "Epoch 297/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2209 - acc: 0.9632 - val_loss: 0.3673 - val_acc: 0.9203\n",
      "Epoch 298/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2203 - acc: 0.9637 - val_loss: 0.3638 - val_acc: 0.9212\n",
      "Epoch 299/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2213 - acc: 0.9636 - val_loss: 0.3646 - val_acc: 0.9208\n",
      "Epoch 300/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2207 - acc: 0.9631 - val_loss: 0.3956 - val_acc: 0.9215\n",
      "Epoch 301/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2186 - acc: 0.9640 - val_loss: 0.3751 - val_acc: 0.9221\n",
      "Epoch 302/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2205 - acc: 0.9635 - val_loss: 0.3639 - val_acc: 0.9211\n",
      "Epoch 303/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2203 - acc: 0.9636 - val_loss: 0.3690 - val_acc: 0.9208\n",
      "Epoch 304/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2206 - acc: 0.9633 - val_loss: 0.3708 - val_acc: 0.9212\n",
      "\n",
      "Epoch 00304: ReduceLROnPlateau reducing learning rate to 0.0001350851875031367.\n",
      "Epoch 305/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2090 - acc: 0.9639 - val_loss: 0.3381 - val_acc: 0.9219\n",
      "Epoch 306/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2097 - acc: 0.9634 - val_loss: 0.3449 - val_acc: 0.9222\n",
      "Epoch 307/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2079 - acc: 0.9639 - val_loss: 0.3596 - val_acc: 0.9220\n",
      "Epoch 308/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2087 - acc: 0.9641 - val_loss: 0.3892 - val_acc: 0.9211\n",
      "Epoch 309/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2083 - acc: 0.9642 - val_loss: 0.3966 - val_acc: 0.9184\n",
      "Epoch 310/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2094 - acc: 0.9637 - val_loss: 0.3701 - val_acc: 0.9173\n",
      "Epoch 311/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2105 - acc: 0.9635 - val_loss: 0.3790 - val_acc: 0.9193\n",
      "Epoch 312/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2091 - acc: 0.9639 - val_loss: 0.3594 - val_acc: 0.9190\n",
      "Epoch 313/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2083 - acc: 0.9640 - val_loss: 0.3842 - val_acc: 0.9208\n",
      "Epoch 314/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.2091 - acc: 0.9641 - val_loss: 0.3606 - val_acc: 0.9199\n",
      "Epoch 315/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2082 - acc: 0.9640 - val_loss: 0.3974 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00315: ReduceLROnPlateau reducing learning rate to 0.00012157666351413355.\n",
      "Epoch 316/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1988 - acc: 0.9641 - val_loss: 0.3752 - val_acc: 0.9199\n",
      "Epoch 317/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2005 - acc: 0.9643 - val_loss: 0.3400 - val_acc: 0.9198\n",
      "Epoch 318/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2004 - acc: 0.9636 - val_loss: 0.3587 - val_acc: 0.9220\n",
      "Epoch 319/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1990 - acc: 0.9645 - val_loss: 0.3604 - val_acc: 0.9218\n",
      "Epoch 320/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1989 - acc: 0.9642 - val_loss: 0.3335 - val_acc: 0.9236\n",
      "Epoch 321/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1999 - acc: 0.9639 - val_loss: 0.3565 - val_acc: 0.9218\n",
      "Epoch 322/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1995 - acc: 0.9643 - val_loss: 0.3675 - val_acc: 0.9204\n",
      "Epoch 323/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1991 - acc: 0.9645 - val_loss: 0.3679 - val_acc: 0.9207\n",
      "Epoch 324/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.2003 - acc: 0.9641 - val_loss: 0.3533 - val_acc: 0.9208\n",
      "Epoch 325/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1996 - acc: 0.9646 - val_loss: 0.3692 - val_acc: 0.9215\n",
      "Epoch 326/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.2000 - acc: 0.9640 - val_loss: 0.3541 - val_acc: 0.9210\n",
      "Epoch 327/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1997 - acc: 0.9638 - val_loss: 0.3586 - val_acc: 0.9213\n",
      "Epoch 328/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1983 - acc: 0.9646 - val_loss: 0.3697 - val_acc: 0.9208\n",
      "Epoch 329/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1986 - acc: 0.9646 - val_loss: 0.3656 - val_acc: 0.9212\n",
      "Epoch 330/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1981 - acc: 0.9645 - val_loss: 0.3585 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00330: ReduceLROnPlateau reducing learning rate to 0.00010941899454337544.\n",
      "Epoch 331/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1901 - acc: 0.9647 - val_loss: 0.3423 - val_acc: 0.9217\n",
      "Epoch 332/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1905 - acc: 0.9645 - val_loss: 0.3535 - val_acc: 0.9207\n",
      "Epoch 333/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1905 - acc: 0.9644 - val_loss: 0.3565 - val_acc: 0.9213\n",
      "Epoch 334/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1897 - acc: 0.9649 - val_loss: 0.3611 - val_acc: 0.9205\n",
      "Epoch 335/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1908 - acc: 0.9649 - val_loss: 0.3423 - val_acc: 0.9215\n",
      "Epoch 336/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1903 - acc: 0.9647 - val_loss: 0.3563 - val_acc: 0.9212\n",
      "Epoch 337/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1900 - acc: 0.9648 - val_loss: 0.3653 - val_acc: 0.9203\n",
      "Epoch 338/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1900 - acc: 0.9645 - val_loss: 0.3429 - val_acc: 0.9213\n",
      "Epoch 339/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1905 - acc: 0.9646 - val_loss: 0.3727 - val_acc: 0.9211\n",
      "Epoch 340/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1897 - acc: 0.9650 - val_loss: 0.3421 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00340: ReduceLROnPlateau reducing learning rate to 9.847709443420172e-05.\n",
      "Epoch 341/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1809 - acc: 0.9650 - val_loss: 0.3564 - val_acc: 0.9201\n",
      "Epoch 342/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1818 - acc: 0.9652 - val_loss: 0.3427 - val_acc: 0.9220\n",
      "Epoch 343/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1810 - acc: 0.9650 - val_loss: 0.3227 - val_acc: 0.9225\n",
      "Epoch 344/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1815 - acc: 0.9649 - val_loss: 0.3568 - val_acc: 0.9202\n",
      "Epoch 345/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1825 - acc: 0.9646 - val_loss: 0.3307 - val_acc: 0.9231\n",
      "Epoch 346/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1818 - acc: 0.9650 - val_loss: 0.3582 - val_acc: 0.9209\n",
      "Epoch 347/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1820 - acc: 0.9650 - val_loss: 0.3373 - val_acc: 0.9221\n",
      "Epoch 348/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1817 - acc: 0.9649 - val_loss: 0.3510 - val_acc: 0.9194\n",
      "Epoch 349/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1817 - acc: 0.9649 - val_loss: 0.3320 - val_acc: 0.9215\n",
      "Epoch 350/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1812 - acc: 0.9656 - val_loss: 0.3542 - val_acc: 0.9208\n",
      "Epoch 351/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1817 - acc: 0.9645 - val_loss: 0.3633 - val_acc: 0.9189\n",
      "Epoch 352/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1811 - acc: 0.9656 - val_loss: 0.3280 - val_acc: 0.9224\n",
      "Epoch 353/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1807 - acc: 0.9651 - val_loss: 0.3378 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00353: ReduceLROnPlateau reducing learning rate to 8.862938630045391e-05.\n",
      "Epoch 354/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1739 - acc: 0.9653 - val_loss: 0.3304 - val_acc: 0.9200\n",
      "Epoch 355/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1744 - acc: 0.9651 - val_loss: 0.3255 - val_acc: 0.9213\n",
      "Epoch 356/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1745 - acc: 0.9651 - val_loss: 0.3199 - val_acc: 0.9220\n",
      "Epoch 357/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1744 - acc: 0.9652 - val_loss: 0.3230 - val_acc: 0.9229\n",
      "Epoch 358/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1748 - acc: 0.9652 - val_loss: 0.3283 - val_acc: 0.9217\n",
      "Epoch 359/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1748 - acc: 0.9648 - val_loss: 0.3193 - val_acc: 0.9229\n",
      "Epoch 360/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1744 - acc: 0.9651 - val_loss: 0.3528 - val_acc: 0.9201\n",
      "Epoch 361/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1745 - acc: 0.9651 - val_loss: 0.3354 - val_acc: 0.9199\n",
      "Epoch 362/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1741 - acc: 0.9651 - val_loss: 0.3345 - val_acc: 0.9200\n",
      "Epoch 363/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1743 - acc: 0.9650 - val_loss: 0.3065 - val_acc: 0.9227\n",
      "Epoch 364/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1746 - acc: 0.9649 - val_loss: 0.3189 - val_acc: 0.9222\n",
      "Epoch 365/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1748 - acc: 0.9648 - val_loss: 0.3257 - val_acc: 0.9224\n",
      "Epoch 366/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1744 - acc: 0.9650 - val_loss: 0.3394 - val_acc: 0.9203\n",
      "Epoch 367/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1746 - acc: 0.9650 - val_loss: 0.3365 - val_acc: 0.9218\n",
      "Epoch 368/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1739 - acc: 0.9652 - val_loss: 0.3407 - val_acc: 0.9207\n",
      "Epoch 369/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1733 - acc: 0.9654 - val_loss: 0.3301 - val_acc: 0.9213\n",
      "Epoch 370/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1748 - acc: 0.9651 - val_loss: 0.3274 - val_acc: 0.9200\n",
      "Epoch 371/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1739 - acc: 0.9653 - val_loss: 0.3370 - val_acc: 0.9199\n",
      "Epoch 372/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1739 - acc: 0.9648 - val_loss: 0.3273 - val_acc: 0.9209\n",
      "Epoch 373/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1745 - acc: 0.9652 - val_loss: 0.3407 - val_acc: 0.9198\n",
      "\n",
      "Epoch 00373: ReduceLROnPlateau reducing learning rate to 7.976644701557234e-05.\n",
      "Epoch 374/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1679 - acc: 0.9650 - val_loss: 0.3181 - val_acc: 0.9206\n",
      "Epoch 375/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1675 - acc: 0.9652 - val_loss: 0.3360 - val_acc: 0.9212\n",
      "Epoch 376/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1675 - acc: 0.9654 - val_loss: 0.3439 - val_acc: 0.9214\n",
      "Epoch 377/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1671 - acc: 0.9653 - val_loss: 0.3420 - val_acc: 0.9218\n",
      "Epoch 378/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1691 - acc: 0.9648 - val_loss: 0.3109 - val_acc: 0.9216\n",
      "Epoch 379/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1680 - acc: 0.9655 - val_loss: 0.3405 - val_acc: 0.9213\n",
      "Epoch 380/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1682 - acc: 0.9655 - val_loss: 0.3342 - val_acc: 0.9216\n",
      "Epoch 381/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1670 - acc: 0.9656 - val_loss: 0.3407 - val_acc: 0.9224\n",
      "Epoch 382/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1683 - acc: 0.9657 - val_loss: 0.3649 - val_acc: 0.9209\n",
      "Epoch 383/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1678 - acc: 0.9654 - val_loss: 0.3092 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00383: ReduceLROnPlateau reducing learning rate to 7.178980231401511e-05.\n",
      "Epoch 384/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1617 - acc: 0.9656 - val_loss: 0.3261 - val_acc: 0.9212\n",
      "Epoch 385/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1610 - acc: 0.9657 - val_loss: 0.2940 - val_acc: 0.9225\n",
      "Epoch 386/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1622 - acc: 0.9656 - val_loss: 0.3261 - val_acc: 0.9209\n",
      "Epoch 387/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1627 - acc: 0.9649 - val_loss: 0.3273 - val_acc: 0.9224\n",
      "Epoch 388/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1623 - acc: 0.9652 - val_loss: 0.3332 - val_acc: 0.9212\n",
      "Epoch 389/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1611 - acc: 0.9657 - val_loss: 0.3196 - val_acc: 0.9226\n",
      "Epoch 390/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1617 - acc: 0.9659 - val_loss: 0.3252 - val_acc: 0.9230\n",
      "Epoch 391/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1626 - acc: 0.9654 - val_loss: 0.3118 - val_acc: 0.9200\n",
      "Epoch 392/400\n",
      "290344/290344 [==============================] - 28s 95us/step - loss: 0.1612 - acc: 0.9659 - val_loss: 0.3213 - val_acc: 0.9208\n",
      "Epoch 393/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1609 - acc: 0.9655 - val_loss: 0.3258 - val_acc: 0.9214\n",
      "Epoch 394/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1617 - acc: 0.9653 - val_loss: 0.3287 - val_acc: 0.9217\n",
      "Epoch 395/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1619 - acc: 0.9659 - val_loss: 0.3178 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00395: ReduceLROnPlateau reducing learning rate to 6.461082011810504e-05.\n",
      "Epoch 396/400\n",
      "290344/290344 [==============================] - 27s 95us/step - loss: 0.1572 - acc: 0.9652 - val_loss: 0.3142 - val_acc: 0.9217\n",
      "Epoch 397/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1550 - acc: 0.9660 - val_loss: 0.3148 - val_acc: 0.9224\n",
      "Epoch 398/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1562 - acc: 0.9660 - val_loss: 0.3122 - val_acc: 0.9210\n",
      "Epoch 399/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1563 - acc: 0.9654 - val_loss: 0.3003 - val_acc: 0.9229\n",
      "Epoch 400/400\n",
      "290344/290344 [==============================] - 27s 94us/step - loss: 0.1564 - acc: 0.9656 - val_loss: 0.3170 - val_acc: 0.9224\n"
     ]
    }
   ],
   "source": [
    "tf.get_default_graph()\n",
    "########## HYPER PARAMETERS\n",
    "\n",
    "batch_size = 500\n",
    "epochs = 400\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "#init=tf.global_variables_initializer()\n",
    "\n",
    "########## HYPER PARAMETERS\n",
    "########## MODEL ARCHITECTURE\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "########## MODEL ARCHITECTURE\n",
    "####TENSORBOARD\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "#### END TENSORBOARD\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Robin_\" + readable_timestamp\n",
    "print(\"KnuckleFinger_Robin_\" + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Robin_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.9, \n",
    "                                            min_lr=0.00001)\n",
    "# compile model for training\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[logger, storer, learning_rate_reduction, tg_callback])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    optimizer = optimizers.Adam()\n",
    "    #optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "    #init=tf.global_variables_initializer()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(27,15,1)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=keras.regularizers.L1L2(0.02, 0.15), use_bias=True))\n",
    "    model.add(Dropout(0.50))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    ########## MODEL ARCHITECTURE\n",
    "    ####TENSORBOARD\n",
    "    config = \"\"\n",
    "    for layer in model.layers:\n",
    "        config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "    #### END TENSORBOARD\n",
    "    config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\"\n",
    "\n",
    "    # Print summary\n",
    "    model.summary()\n",
    "    readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "    tensorflowfolder = \"/srv/share/tensorboardfiles/KnuckleFinger_Robin_\" + readable_timestamp\n",
    "    print(\"KnuckleFinger_Robin_\" + readable_timestamp)\n",
    "    logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                                write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "    storer = ModelCheckpoint(\"./ModelSnapshots/KnuckleFinger_Robin_\" + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                patience=10, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.95, \n",
    "                                                min_lr=0.00001)\n",
    "    # compile model for training\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[ storer,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model for inference to get test accuracy\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig(\"pres.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"10_01_19.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8380899e-01, 1.6190920e-02],\n",
       "       [9.9928612e-01, 7.1396033e-04],\n",
       "       [9.8458582e-01, 1.5414230e-02],\n",
       "       ...,\n",
       "       [7.4371819e-05, 9.9992561e-01],\n",
       "       [1.7390951e-07, 9.9999988e-01],\n",
       "       [1.8832952e-06, 9.9999809e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train, batch_size=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction=np.round(model.predict(x_train))\n",
    "train_prediction=train_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction=np.round(model.predict(x_test))\n",
    "val_prediction=val_prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = val_prediction - y_test_one_hot\n",
    "indices = []\n",
    "for i in range(len(val_prediction)):\n",
    "    if np.count_nonzero(delta[i]) > 0:\n",
    "        indices += [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3545"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df9b4718d4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimagelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "imagelist = []\n",
    "for data_point in indices:\n",
    "    print(data_point)\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    #plt.subplot(figsize=(6,6))\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_point = indices[0]\n",
    "    data = df_train.Blobs.iloc[data_point]\n",
    "    label = \"Knuckle\" if train_prediction[data_point][0] == 1 else \"Finger\"  \n",
    "    ax.set_title(\"Input method: \" + str(df_train.InputMethod.iloc[data_point]) + \"\\n\" + \"Label as: \"  + label)\n",
    "    #plt.imsave(\"PredictionImages/\" + str(data_point)+\".pdf\", data, cmap='gray', vmin=0, vmax=255)\n",
    "    plt.imsave(\"PredictionImages/{}.png\".format(data_point), data, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    #plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
