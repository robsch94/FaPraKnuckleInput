{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras import utils\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing matplotlib to plot images.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing SK-learn to calculate precision and recall\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.utils import shuffle \n",
    "\n",
    "# Used for graph export\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "from keras import backend as K\n",
    "\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telegram\n",
    "from keras.callbacks import Callback\n",
    "from callbacks import TelegramCallback\n",
    "from callbacks.TelegramData import TelegramData\n",
    "\n",
    "\n",
    "# create callback\n",
    "config = {\n",
    "    'token': TelegramData.Token,   # paste your bot token\n",
    "    'telegram_id': TelegramData.ID,                                   # paste your telegram_id\n",
    "    'model_name': 'Jan_LSTM_noreg'\n",
    "}\n",
    "\n",
    "tg_callback = TelegramCallback(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingTensorBoard(TensorBoard):    \n",
    "\n",
    "    def __init__(self, log_dir, settings_str_to_log, **kwargs):\n",
    "        super(LoggingTensorBoard, self).__init__(log_dir, **kwargs)\n",
    "\n",
    "        self.settings_str = settings_str_to_log\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        TensorBoard.on_train_begin(self, logs=logs)\n",
    "\n",
    "        tensor =  tf.convert_to_tensor(self.settings_str)\n",
    "        summary = tf.summary.text (\"Run_Settings\", tensor)\n",
    "\n",
    "        with  tf.Session() as sess:\n",
    "            s = sess.run(summary)\n",
    "            self.writer.add_summary(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  6 14  4  2  1 12 16  7 18  5 13  3] [11 17 10  8  9]\n"
     ]
    }
   ],
   "source": [
    "dfAll = pd.read_pickle(\"PklData/df_lstm_norm50.pkl\")\n",
    "\n",
    "lst = dfAll.userID.unique()\n",
    "np.random.seed(1337)\n",
    "np.random.shuffle(lst)\n",
    "test_ids = lst[-5:]\n",
    "train_ids = lst[:-5]\n",
    "print(train_ids, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll.userID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAll.TaskID = dfAll.TaskID % 17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfAll[dfAll.userID.isin(train_ids)]\n",
    "df_test = dfAll[dfAll.userID.isin(test_ids)]\n",
    "\n",
    "df_train2 = df_train[['Blobs', 'TaskID']].copy()\n",
    "df_test2 = df_test[['Blobs', 'TaskID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(df_train2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "x_test = np.concatenate(df_test2.Blobs.values).reshape(-1,50,27,15,1)\n",
    "\n",
    "y_train = df_train2.TaskID.values\n",
    "y_test = df_test2.TaskID.values\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices (one-hot notation)\n",
    "num_classes = len(dfAll.TaskID.unique())\n",
    "y_train_one_hot = utils.to_categorical(df_train2.TaskID, num_classes)\n",
    "y_test_one_hot = utils.to_categorical(df_test2.TaskID, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "#config = tf.ConfigProto(device_count = {\"GPU\": 1})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "config.allow_soft_placement = True\n",
    "config.gpu_options.allow_growth=True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "# set session config\n",
    "tf.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_31 (TimeDis (None, 50, 27, 15, 64)    640       \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 50, 27, 15, 32)    18464     \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 50, 14, 8, 32)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 50, 14, 8, 32)     9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 50, 14, 8, 16)     4624      \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 50, 7, 4, 16)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 50, 7, 4, 16)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 50, 448)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 50, 128)           57472     \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 50, 250)           379000    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 50, 250)           0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               140400    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 17)                1717      \n",
      "=================================================================\n",
      "Total params: 611,565\n",
      "Trainable params: 611,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KnuckleFinger_LSTM_Jan_noreg20190301_105003\n",
      "Train on 7044 samples, validate on 2149 samples\n",
      "Epoch 1/5000\n",
      "7044/7044 [==============================] - 94s 13ms/step - loss: 2.7038 - acc: 0.1126 - val_loss: 2.6979 - val_acc: 0.1238\n",
      "Epoch 2/5000\n",
      "7044/7044 [==============================] - 91s 13ms/step - loss: 2.5433 - acc: 0.1596 - val_loss: 2.4722 - val_acc: 0.1819\n",
      "Epoch 3/5000\n",
      "7044/7044 [==============================] - 95s 14ms/step - loss: 2.3965 - acc: 0.2007 - val_loss: 2.2970 - val_acc: 0.2503\n",
      "Epoch 4/5000\n",
      "7044/7044 [==============================] - 69s 10ms/step - loss: 2.0602 - acc: 0.3068 - val_loss: 1.9456 - val_acc: 0.3765\n",
      "Epoch 5/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 1.5467 - acc: 0.5109 - val_loss: 1.3600 - val_acc: 0.6110\n",
      "Epoch 6/5000\n",
      "7044/7044 [==============================] - 90s 13ms/step - loss: 1.0663 - acc: 0.7105 - val_loss: 1.1069 - val_acc: 0.6859\n",
      "Epoch 7/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.8044 - acc: 0.7907 - val_loss: 0.8314 - val_acc: 0.7776\n",
      "Epoch 8/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.6755 - acc: 0.8225 - val_loss: 0.7645 - val_acc: 0.8036\n",
      "Epoch 9/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.6051 - acc: 0.8455 - val_loss: 0.6867 - val_acc: 0.8046\n",
      "Epoch 10/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.5346 - acc: 0.8630 - val_loss: 0.6850 - val_acc: 0.8176\n",
      "Epoch 11/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.4885 - acc: 0.8744 - val_loss: 0.6647 - val_acc: 0.8143\n",
      "Epoch 12/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.4604 - acc: 0.8779 - val_loss: 0.6532 - val_acc: 0.8208\n",
      "Epoch 13/5000\n",
      "7044/7044 [==============================] - 104s 15ms/step - loss: 0.4252 - acc: 0.8890 - val_loss: 0.6036 - val_acc: 0.8390\n",
      "Epoch 14/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.4070 - acc: 0.8894 - val_loss: 0.5718 - val_acc: 0.8455\n",
      "Epoch 15/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.3655 - acc: 0.9043 - val_loss: 0.5127 - val_acc: 0.8613\n",
      "Epoch 16/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.3679 - acc: 0.9020 - val_loss: 0.4999 - val_acc: 0.8544\n",
      "Epoch 17/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.3450 - acc: 0.9077 - val_loss: 0.5664 - val_acc: 0.8446\n",
      "Epoch 18/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.3166 - acc: 0.9182 - val_loss: 0.5796 - val_acc: 0.8255\n",
      "Epoch 19/5000\n",
      "7044/7044 [==============================] - 104s 15ms/step - loss: 0.3224 - acc: 0.9116 - val_loss: 0.5467 - val_acc: 0.8502\n",
      "Epoch 20/5000\n",
      "7044/7044 [==============================] - 105s 15ms/step - loss: 0.3017 - acc: 0.9214 - val_loss: 0.5610 - val_acc: 0.8478\n",
      "Epoch 21/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.2775 - acc: 0.9252 - val_loss: 0.4821 - val_acc: 0.8664\n",
      "Epoch 22/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.2763 - acc: 0.9235 - val_loss: 0.5259 - val_acc: 0.8520\n",
      "Epoch 23/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.2597 - acc: 0.9262 - val_loss: 0.5372 - val_acc: 0.8530\n",
      "Epoch 24/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.2495 - acc: 0.9334 - val_loss: 0.5632 - val_acc: 0.8557\n",
      "Epoch 25/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.2411 - acc: 0.9337 - val_loss: 0.4878 - val_acc: 0.8590\n",
      "Epoch 26/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.2305 - acc: 0.9398 - val_loss: 0.5086 - val_acc: 0.8692\n",
      "Epoch 27/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.2274 - acc: 0.9407 - val_loss: 0.5049 - val_acc: 0.8623\n",
      "Epoch 28/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.2211 - acc: 0.9363 - val_loss: 0.4810 - val_acc: 0.8660\n",
      "Epoch 29/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.2020 - acc: 0.9465 - val_loss: 0.5167 - val_acc: 0.8637\n",
      "Epoch 30/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.2005 - acc: 0.9449 - val_loss: 0.5324 - val_acc: 0.8595\n",
      "Epoch 31/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1953 - acc: 0.9468 - val_loss: 0.5112 - val_acc: 0.8581\n",
      "Epoch 32/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1942 - acc: 0.9485 - val_loss: 0.5007 - val_acc: 0.8688\n",
      "Epoch 33/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1937 - acc: 0.9482 - val_loss: 0.5023 - val_acc: 0.8664\n",
      "Epoch 34/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1766 - acc: 0.9524 - val_loss: 0.4729 - val_acc: 0.8739\n",
      "Epoch 35/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1785 - acc: 0.9530 - val_loss: 0.4859 - val_acc: 0.8716\n",
      "Epoch 36/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1693 - acc: 0.9541 - val_loss: 0.4685 - val_acc: 0.8730\n",
      "Epoch 37/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.1635 - acc: 0.9543 - val_loss: 0.4431 - val_acc: 0.8781\n",
      "Epoch 38/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1580 - acc: 0.9584 - val_loss: 0.4833 - val_acc: 0.8730\n",
      "Epoch 39/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1560 - acc: 0.9588 - val_loss: 0.4861 - val_acc: 0.8730\n",
      "Epoch 40/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1478 - acc: 0.9611 - val_loss: 0.5260 - val_acc: 0.8604\n",
      "Epoch 41/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1532 - acc: 0.9571 - val_loss: 0.4516 - val_acc: 0.8711\n",
      "Epoch 42/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1449 - acc: 0.9634 - val_loss: 0.4420 - val_acc: 0.8823\n",
      "Epoch 43/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1446 - acc: 0.9602 - val_loss: 0.4542 - val_acc: 0.8795\n",
      "Epoch 44/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1467 - acc: 0.9598 - val_loss: 0.4793 - val_acc: 0.8706\n",
      "Epoch 45/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1405 - acc: 0.9628 - val_loss: 0.4568 - val_acc: 0.8795\n",
      "Epoch 46/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1348 - acc: 0.9620 - val_loss: 0.4844 - val_acc: 0.8799\n",
      "Epoch 47/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1401 - acc: 0.9615 - val_loss: 0.5010 - val_acc: 0.8697\n",
      "Epoch 48/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1341 - acc: 0.9654 - val_loss: 0.4593 - val_acc: 0.8823\n",
      "Epoch 49/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1216 - acc: 0.9659 - val_loss: 0.4931 - val_acc: 0.8720\n",
      "Epoch 50/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1113 - acc: 0.9705 - val_loss: 0.4556 - val_acc: 0.8860\n",
      "Epoch 51/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1198 - acc: 0.9661 - val_loss: 0.4544 - val_acc: 0.8804\n",
      "Epoch 52/5000\n",
      "7044/7044 [==============================] - 103s 15ms/step - loss: 0.1282 - acc: 0.9644 - val_loss: 0.5106 - val_acc: 0.8748\n",
      "Epoch 53/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1192 - acc: 0.9666 - val_loss: 0.5420 - val_acc: 0.8646\n",
      "Epoch 54/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1120 - acc: 0.9712 - val_loss: 0.4742 - val_acc: 0.8748\n",
      "Epoch 55/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1075 - acc: 0.9710 - val_loss: 0.5206 - val_acc: 0.8618\n",
      "Epoch 56/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1164 - acc: 0.9676 - val_loss: 0.4785 - val_acc: 0.8739\n",
      "Epoch 57/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.1140 - acc: 0.9699 - val_loss: 0.4967 - val_acc: 0.8804\n",
      "Epoch 58/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1050 - acc: 0.9710 - val_loss: 0.4489 - val_acc: 0.8846\n",
      "Epoch 59/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.1042 - acc: 0.9723 - val_loss: 0.5408 - val_acc: 0.8548\n",
      "Epoch 60/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1081 - acc: 0.9688 - val_loss: 0.4856 - val_acc: 0.8795\n",
      "Epoch 61/5000\n",
      "7044/7044 [==============================] - 102s 15ms/step - loss: 0.0921 - acc: 0.9766 - val_loss: 0.4810 - val_acc: 0.8799\n",
      "Epoch 62/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0989 - acc: 0.9722 - val_loss: 0.4719 - val_acc: 0.8851\n",
      "Epoch 63/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.1010 - acc: 0.9729 - val_loss: 0.4691 - val_acc: 0.8855\n",
      "Epoch 64/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0972 - acc: 0.9717 - val_loss: 0.4981 - val_acc: 0.8720\n",
      "Epoch 65/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.0949 - acc: 0.9735 - val_loss: 0.5790 - val_acc: 0.8660\n",
      "Epoch 66/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.0923 - acc: 0.9744 - val_loss: 0.5566 - val_acc: 0.8697\n",
      "Epoch 67/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0804 - acc: 0.9793 - val_loss: 0.5839 - val_acc: 0.8604\n",
      "Epoch 68/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0919 - acc: 0.9740 - val_loss: 0.5336 - val_acc: 0.8753\n",
      "Epoch 69/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.1081 - acc: 0.9712 - val_loss: 0.5528 - val_acc: 0.8683\n",
      "Epoch 70/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0900 - acc: 0.9744 - val_loss: 0.5190 - val_acc: 0.8809\n",
      "Epoch 71/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0930 - acc: 0.9740 - val_loss: 0.5865 - val_acc: 0.8618\n",
      "Epoch 72/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0872 - acc: 0.9761 - val_loss: 0.5201 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 9.499999760009814e-05.\n",
      "Epoch 73/5000\n",
      "7044/7044 [==============================] - 98s 14ms/step - loss: 0.0787 - acc: 0.9793 - val_loss: 0.5376 - val_acc: 0.8837\n",
      "Epoch 74/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0803 - acc: 0.9806 - val_loss: 0.5722 - val_acc: 0.8669\n",
      "Epoch 75/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0760 - acc: 0.9791 - val_loss: 0.5300 - val_acc: 0.8711\n",
      "Epoch 76/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.0718 - acc: 0.9800 - val_loss: 0.5573 - val_acc: 0.8753\n",
      "Epoch 77/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0856 - acc: 0.9764 - val_loss: 0.5064 - val_acc: 0.8799\n",
      "Epoch 78/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0819 - acc: 0.9791 - val_loss: 0.5229 - val_acc: 0.8744\n",
      "Epoch 79/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0825 - acc: 0.9767 - val_loss: 0.4920 - val_acc: 0.8790\n",
      "Epoch 80/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0760 - acc: 0.9798 - val_loss: 0.5119 - val_acc: 0.8758\n",
      "Epoch 81/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0753 - acc: 0.9804 - val_loss: 0.5292 - val_acc: 0.8753\n",
      "Epoch 82/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0676 - acc: 0.9830 - val_loss: 0.4742 - val_acc: 0.8804\n",
      "Epoch 83/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0619 - acc: 0.9824 - val_loss: 0.5244 - val_acc: 0.8753\n",
      "Epoch 84/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.0608 - acc: 0.9838 - val_loss: 0.4993 - val_acc: 0.8809\n",
      "Epoch 85/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0627 - acc: 0.9825 - val_loss: 0.5420 - val_acc: 0.8748\n",
      "Epoch 86/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0722 - acc: 0.9791 - val_loss: 0.5301 - val_acc: 0.8818\n",
      "Epoch 87/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0724 - acc: 0.9811 - val_loss: 0.5333 - val_acc: 0.8772\n",
      "Epoch 88/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0668 - acc: 0.9820 - val_loss: 0.7035 - val_acc: 0.8506\n",
      "Epoch 89/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0722 - acc: 0.9793 - val_loss: 0.5413 - val_acc: 0.8753\n",
      "Epoch 90/5000\n",
      "7044/7044 [==============================] - 102s 14ms/step - loss: 0.0595 - acc: 0.9845 - val_loss: 0.5441 - val_acc: 0.8790\n",
      "Epoch 91/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0676 - acc: 0.9811 - val_loss: 0.5724 - val_acc: 0.8744\n",
      "Epoch 92/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0561 - acc: 0.9861 - val_loss: 0.5345 - val_acc: 0.8799\n",
      "Epoch 93/5000\n",
      "7044/7044 [==============================] - 101s 14ms/step - loss: 0.0578 - acc: 0.9852 - val_loss: 0.5655 - val_acc: 0.8772\n",
      "Epoch 94/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0555 - acc: 0.9857 - val_loss: 0.5860 - val_acc: 0.8725\n",
      "Epoch 95/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0645 - acc: 0.9828 - val_loss: 0.5444 - val_acc: 0.8832\n",
      "Epoch 96/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0578 - acc: 0.9838 - val_loss: 0.6355 - val_acc: 0.8641\n",
      "Epoch 97/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0546 - acc: 0.9838 - val_loss: 0.5018 - val_acc: 0.8865\n",
      "Epoch 98/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0723 - acc: 0.9810 - val_loss: 0.5244 - val_acc: 0.8837\n",
      "Epoch 99/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0601 - acc: 0.9830 - val_loss: 0.5409 - val_acc: 0.8813\n",
      "Epoch 100/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0606 - acc: 0.9832 - val_loss: 0.5336 - val_acc: 0.8855\n",
      "Epoch 101/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0584 - acc: 0.9837 - val_loss: 0.5711 - val_acc: 0.8795\n",
      "Epoch 102/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0501 - acc: 0.9871 - val_loss: 0.5659 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 9.02499959920533e-05.\n",
      "Epoch 103/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0556 - acc: 0.9851 - val_loss: 0.5648 - val_acc: 0.8753\n",
      "Epoch 104/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0529 - acc: 0.9851 - val_loss: 0.5302 - val_acc: 0.8869\n",
      "Epoch 105/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0501 - acc: 0.9862 - val_loss: 0.6325 - val_acc: 0.8706\n",
      "Epoch 106/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0471 - acc: 0.9862 - val_loss: 0.5721 - val_acc: 0.8748\n",
      "Epoch 107/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0425 - acc: 0.9881 - val_loss: 0.5680 - val_acc: 0.8804\n",
      "Epoch 108/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0456 - acc: 0.9879 - val_loss: 0.5728 - val_acc: 0.8823\n",
      "Epoch 109/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0442 - acc: 0.9874 - val_loss: 0.5675 - val_acc: 0.8767\n",
      "Epoch 110/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0451 - acc: 0.9886 - val_loss: 0.5592 - val_acc: 0.8795\n",
      "Epoch 111/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0495 - acc: 0.9868 - val_loss: 0.6089 - val_acc: 0.8753\n",
      "Epoch 112/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0443 - acc: 0.9889 - val_loss: 0.5621 - val_acc: 0.8776\n",
      "Epoch 113/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0375 - acc: 0.9908 - val_loss: 0.5812 - val_acc: 0.8758\n",
      "Epoch 114/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0414 - acc: 0.9885 - val_loss: 0.6082 - val_acc: 0.8739\n",
      "Epoch 115/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0392 - acc: 0.9882 - val_loss: 0.5931 - val_acc: 0.8813\n",
      "Epoch 116/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0470 - acc: 0.9875 - val_loss: 0.6019 - val_acc: 0.8739\n",
      "Epoch 117/5000\n",
      "7044/7044 [==============================] - 99s 14ms/step - loss: 0.0494 - acc: 0.9859 - val_loss: 0.6036 - val_acc: 0.8809\n",
      "Epoch 118/5000\n",
      "7044/7044 [==============================] - 100s 14ms/step - loss: 0.0515 - acc: 0.9848 - val_loss: 0.6580 - val_acc: 0.8720\n",
      "Epoch 119/5000\n",
      "3250/7044 [============>.................] - ETA: 49s - loss: 0.0618 - acc: 0.9828"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 5000\n",
    "timesteps = 50\n",
    "data_dim = (27,15)\n",
    "l1v = 0.007\n",
    "l2v = 0.014\n",
    "\n",
    "\n",
    "tf.get_default_graph()\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=(3,3), activation='relu', \n",
    "                                 padding='same'), input_shape=(timesteps ,27, 15, 1)))\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.50)))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "            padding='same', input_shape=(timesteps ,27, 15, 1))))\n",
    "model.add(TimeDistributed(Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=None, padding='same', data_format='channels_last')))\n",
    "model.add(TimeDistributed(Dropout(0.50)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "#model.add(TimeDistributed(Dense(128)))\n",
    "model.add(TimeDistributed(Dense(128)))\n",
    "#model.add(TimeDistributed(Dense(32)))\n",
    "model.add(LSTM(250, return_sequences=True, input_shape=(timesteps, data_dim)))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(LSTM(256, return_sequences=True, input_shape=(timesteps, data_dim),kernel_regularizer=regularizers.l1_l2(0.001,0.01)))\n",
    "#model.add(Dense(512))\n",
    "model.add(LSTM(100, return_sequences=False, input_shape=(timesteps, data_dim)))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(Dense(256))\n",
    "#model.add(LSTM(64, kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(Dropout(0.20))\n",
    "#model.add(Dense(64))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#optimizer = optimizers.Adagrad()\n",
    "optimizer = optimizers.Adam(lr = 0.0001, decay=1e-6)\n",
    "#optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Broadcast progress to the tensorboard.\n",
    "\n",
    "config = \"\"\n",
    "for layer in model.layers:\n",
    "    config += str(layer.output).split('\\\"')[1].split(\"/\")[0] + str(layer.output_shape) + \"\\n\\n\"\n",
    "config += \"batchsize: \" + str(batch_size) + \"\\n\\n\" + \"epochs: \" + str(epochs) + \"\\n\\n\" \n",
    "config += \"l1: \" + str(l1v) + \"\\n\\n\" + \"l2: \" + str(l2v) + \"\\n\\n\"\n",
    "\n",
    "model.summary()\n",
    "current_name = \"KnuckleFinger_LSTM_Jan_noreg\"\n",
    "readable_timestamp = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "tensorflowfolder = \"/srv/share/tensorboardfiles/\" + current_name + readable_timestamp\n",
    "print(current_name + readable_timestamp)\n",
    "logger = LoggingTensorBoard(settings_str_to_log = config, log_dir=tensorflowfolder, histogram_freq=0,\n",
    "                            write_graph=True, write_images=True, update_freq = 'epoch')\n",
    "storer = ModelCheckpoint(\"./ModelSnapshots/\" + current_name + readable_timestamp + \".h5\", monitor='val_loss', verbose=0,\n",
    "                         save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=30, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.95, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x_train, y_train_one_hot,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test_one_hot),\n",
    "                        callbacks=[storer,logger,tg_callback, learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lstm_28_02_19_inter_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_acc'], label=\"Test Accuracy\")\n",
    "plt.plot(history.history['acc'], label=\"Training Accuracy\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict(x_test, batch_size=30)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "#model.predict(x_test)\n",
    "\n",
    "print ('\\n Summary of the precision, recall, F1 score for each class:')\n",
    "print (sklearn.metrics.classification_report(y_test, y_test_pred))\n",
    "\n",
    "print ('\\n Confusion matrix: ')\n",
    "print (sklearn.metrics.confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
