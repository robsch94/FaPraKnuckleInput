{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing for LSTM: Blobdetection and Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.odr import *\n",
    "from scipy.stats import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import scipy\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, LeavePOut\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Vector2:\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Vector2(self.x + other.x, self.y + other.y)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return Vector2(other.x + self.x, other.y + self.y)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return Vector2(self.x - other.x, self.y - other.y)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return Vector2(self.x * other, self.y * other)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return Vector2(other * self.x, other * self.y)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return Vector2(self.x / other, self.y / other)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"(\" + str(self.x) + \",\" + str(self.y) + \")\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.x == other.x and self.y == other.y\n",
    "        return False\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        if self.y > other.y:\n",
    "            return False\n",
    "        elif self.y < other.y:\n",
    "            return True\n",
    "        return self.x < other.x\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        if self.y > other.y:\n",
    "            return False\n",
    "        elif self.y < other.y:\n",
    "            return True\n",
    "        return self.x <= other.x\n",
    "    \n",
    "    def __gt__(self, other):\n",
    "        if self.y < other.y:\n",
    "            return False\n",
    "        elif self.y > other.y:\n",
    "            return True\n",
    "        return self.x > other.x\n",
    "    \n",
    "    def __ge__(self, other):\n",
    "        if self.y < other.y:\n",
    "            return False\n",
    "        elif self.y > other.y:\n",
    "            return True\n",
    "        return self.x >= other.x\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash((self.x, self.y))\n",
    "\n",
    "    def magnitude(self):\n",
    "        return math.sqrt(self.x * self.x + self.y * self.y)\n",
    "\n",
    "    @staticmethod\n",
    "    def zero():\n",
    "        return Vector2(0, 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(vector):\n",
    "        return vector / vector.magnitude()\n",
    "\n",
    "    @staticmethod\n",
    "    def dot(a, b):\n",
    "        return a.x * b.x + a.y * b.y\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross(a, b):\n",
    "        return (a.x * b.y) - (a.y * b.x)\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(a, b):\n",
    "        return Vector2(a.x - b.x, a.y - b.y).magnitude()\n",
    "\n",
    "    @staticmethod\n",
    "    def angle(a, b):\n",
    "        if Vector2.cross(a, b) < 0:\n",
    "            return -1.0 * np.arccos(Vector2.dot(a, b) / (a.magnitude() * b.magnitude()))\n",
    "        return np.arccos(Vector2.dot(a, b) / (a.magnitude() * b.magnitude()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.read_pickle(\"PklData/dfFiltered_LSTM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.Image = df_filtered.Image.apply(lambda x: x.reshape(27, 15))\n",
    "df_filtered.Image = df_filtered.Image.apply(lambda x: x.clip(min=0, max=255))\n",
    "df_filtered.Image = df_filtered.Image.apply(lambda x: x.astype(np.uint8))\n",
    "df_filtered[\"ImageSum\"] = df_filtered.Image.apply(lambda x: np.sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTMs new Blob detection (only detect, if there are blobs)\n",
    "def detect_blobs(image):\n",
    "    #image = image.reshape(27, 15)\n",
    "    large = np.ones((29,17), dtype=np.uint8)\n",
    "    large[1:28,1:16] = image\n",
    "    temp, thresh = cv2.threshold(cv2.bitwise_not(large), 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [a for a in contours if cv2.contourArea(a) > 8 and cv2.contourArea(a) < 255]\n",
    "    lstBlob  = []\n",
    "    lstMin = []\n",
    "    lstMax = []\n",
    "    count = 0\n",
    "    return len(contours) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pool = Pool(cpu_count() - 1)\n",
    "temp_blobs = pool.map(detect_blobs, df_filtered.Image)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[\"ContainsBlobs\"] = temp_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label if knuckle or finger\n",
    "def f(row):\n",
    "    if row['TaskID'] < 17:\n",
    "        #val = \"Knuckle\"\n",
    "        val = 0\n",
    "    elif row['TaskID'] >= 17:\n",
    "        #val = \"Finger\"\n",
    "        val = 1\n",
    "    return val\n",
    "df_filtered['InputMethod'] = df_filtered.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: some timestamps are strings (XXXXE+XXXX) which is not accurate enough, switching to index instead\n",
    "\"\"\"def cast_to_int(x):\n",
    "    if type(x) == int:\n",
    "        return x\n",
    "    x = str(x).replace(\",\", \".\")\n",
    "    return int(float(x))\n",
    "\n",
    "df_filtered.Timestamp = df_filtered.Timestamp.map(cast_to_int)\"\"\"\n",
    "df_filtered.index = range(len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# trim image sequences down to only between first and last detected blob\n",
    "UserIDs = []\n",
    "TaskIDs = []\n",
    "VersionIDs = []\n",
    "Blobs = []\n",
    "for userID in df_filtered.userID.unique():\n",
    "    print(userID)\n",
    "    for TaskID in df_filtered[df_filtered.userID == userID].TaskID.unique():\n",
    "        for VersionID in df_filtered[(df_filtered.userID == userID) & (df_filtered.TaskID == TaskID)].VersionID.unique():\n",
    "            first_blob = -1\n",
    "            last_blob = -1\n",
    "            for index, row in df_filtered[(df_filtered.userID == userID) & (df_filtered.TaskID == TaskID) & (df_filtered.VersionID == VersionID)].iterrows():\n",
    "                if row.ContainsBlobs:\n",
    "                    last_blob = index\n",
    "                    if first_blob == -1:\n",
    "                        first_blob = index\n",
    "            if first_blob >= 0 and last_blob >= 0:\n",
    "                UserIDs.append(userID)\n",
    "                TaskIDs.append(TaskID)\n",
    "                VersionIDs.append(VersionID)\n",
    "                Blobs.append(df_filtered[(df_filtered.userID == userID) & (df_filtered.TaskID == TaskID) & (df_filtered.VersionID == VersionID) & (df_filtered.index >= first_blob) & (df_filtered.index <= last_blob)].Image.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserIDs = np.array(UserIDs, dtype=np.int64)\n",
    "TaskIDs = np.array(TaskIDs, dtype=np.int64)\n",
    "VersionIDs = np.array(VersionIDs, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_all = pd.DataFrame()\n",
    "df_lstm_all[\"userID\"] = UserIDs\n",
    "df_lstm_all[\"TaskID\"] = TaskIDs\n",
    "df_lstm_all[\"VersionID\"] = VersionIDs\n",
    "df_lstm_all[\"Blobs\"] = Blobs\n",
    "df_lstm_all.Blobs = df_lstm_all.Blobs.map(np.array)\n",
    "df_lstm_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for index, row in df_lstm_all.iterrows():\n",
    "    lengths.append(row.Blobs.shape[0])\n",
    "df_lstm_all[\"BlobCount\"] = lengths\n",
    "# add a column for pure gesture recognition without finger/knuckle\n",
    "df_lstm_all[\"GestureOnly\"] = df_lstm_all.TaskID % 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_all.BlobCount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_all.groupby(df_lstm_all.GestureOnly)[\"BlobCount\"].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on gesture lengths\n",
    "print(\"before: %s\" % len(df_lstm_all))\n",
    "df_lstm = df_lstm_all[(df_lstm_all.BlobCount <= 100) & (df_lstm_all.BlobCount >= 5)]\n",
    "print(\"after: %s\" % len(df_lstm))\n",
    "print(\"ratio: %s\" % ((len(df_lstm_all) - len(df_lstm)) / len(df_lstm_all) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.BlobCount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for index, row in df_lstm.iterrows():\n",
    "    lengths.append(row.Blobs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm[\"BlobCount\"] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.to_pickle('PklData/df_lstm2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.BlobCount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(a, b, c=0.5):\n",
    "    return c * b + (1.0 - c) * a\n",
    "\n",
    "#Svens new Blob detection\n",
    "def detect_blobs_return(image, task):\n",
    "    #image = e.Image\n",
    "    large = np.ones((29,17), dtype=np.uint8)\n",
    "    large[1:28,1:16] = np.copy(image)\n",
    "    temp, thresh = cv2.threshold(cv2.bitwise_not(large), 205, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [a for a in contours if cv2.contourArea(a) > 8 and cv2.contourArea(a) < 255]\n",
    "    lstBlob  = []\n",
    "    lstCenter = []\n",
    "    lstMin = []\n",
    "    lstMax = []\n",
    "    count = 0\n",
    "    contours.sort(key=lambda a: cv2.contourArea(a))\n",
    "    if len(contours) > 0:\n",
    "        # if two finger or knuckle\n",
    "        cont_count = 2 if task in [1, 6, 7, 18, 23, 24] and len(contours) > 1 else 1\n",
    "        for i in range(1, cont_count + 1):\n",
    "            max_contour = contours[-1 * i]\n",
    "            xmax, ymax = np.max(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            xmin, ymin = np.min(max_contour.reshape(len(max_contour),2), axis=0)\n",
    "            M = cv2.moments(max_contour)\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"]) - 1\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"]) - 1\n",
    "            #croped_im = np.zeros((27,15))\n",
    "            blob = large[max(ymin - 1, 0):min(ymax + 1, large.shape[0]),max(xmin - 1, 0):min(xmax + 1, large.shape[1])]\n",
    "            #croped_im[0:blob.shape[0],0:blob.shape[1]] = blob\n",
    "            #return (1, [croped_im])\n",
    "            lstBlob.append(blob)\n",
    "            lstCenter.append((cY, cX))\n",
    "            lstMin.append(xmax-xmin)\n",
    "            lstMax.append(ymax-ymin)\n",
    "            count = count + 1\n",
    "        return (count, lstBlob, lstCenter)\n",
    "    else:\n",
    "        return (0, [np.zeros((29, 19))], 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detects, which blob in the first image corresponds to which blob in the second image\n",
    "# (depending on the distances between blobs)\n",
    "def create_blob_tuples(im_a, im_b, task_id):\n",
    "    blob_det_a = detect_blobs_return(im_a, task_id)\n",
    "    blob_det_b = detect_blobs_return(im_b, task_id)\n",
    "    blob_tuples = []\n",
    "    if blob_det_a[0] == blob_det_b[0] == 2:\n",
    "        M = cv2.moments(blob_det_a[1][0])\n",
    "        cX_a_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_a_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_a[1][1])\n",
    "        cX_a_1 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_a_1 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_b[1][0])\n",
    "        cX_b_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_b_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_b[1][1])\n",
    "        cX_b_1 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_b_1 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        dist_1 = Vector2.magnitude(Vector2(cX_a_0 - cX_b_0, cY_a_0 - cY_b_0))\n",
    "        dist_2 = Vector2.magnitude(Vector2(cX_a_0 - cX_b_1, cY_a_0 - cY_b_1))\n",
    "        if(dist_1 <= dist_2):\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_b[1][0], blob_det_a[2][0], blob_det_b[2][0]))\n",
    "            blob_tuples.append((blob_det_a[1][1], blob_det_b[1][1], blob_det_a[2][1], blob_det_b[2][1]))\n",
    "        else:\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_b[1][1], blob_det_a[2][0], blob_det_b[2][1]))\n",
    "            blob_tuples.append((blob_det_a[1][1], blob_det_b[1][0], blob_det_a[2][1], blob_det_b[2][0]))\n",
    "    elif blob_det_a[0] == 1 and blob_det_b[0] == 2:\n",
    "        M = cv2.moments(blob_det_a[1][0])\n",
    "        cX_a_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_a_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_b[1][0])\n",
    "        cX_b_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_b_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_b[1][1])\n",
    "        cX_b_1 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_b_1 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        dist_1 = Vector2.magnitude(Vector2(cX_a_0 - cX_b_0, cY_a_0 - cY_b_0))\n",
    "        dist_2 = Vector2.magnitude(Vector2(cX_a_0 - cX_b_1, cY_a_0 - cY_b_1))\n",
    "        if(dist_1 <= dist_2):\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_b[1][0], blob_det_a[2][0], blob_det_b[2][0]))\n",
    "            blob_tuples.append((blob_det_b[1][1], blob_det_b[1][1], blob_det_b[2][1], blob_det_b[2][1]))\n",
    "        else:\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_b[1][1], blob_det_a[2][0], blob_det_b[2][1]))\n",
    "            blob_tuples.append((blob_det_b[1][0], blob_det_b[1][0], blob_det_b[2][0], blob_det_b[2][0]))\n",
    "    elif blob_det_a[0] == 2 and blob_det_b[0] == 1:\n",
    "        M = cv2.moments(blob_det_a[1][0])\n",
    "        cX_a_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_a_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_a[1][1])\n",
    "        cX_a_1 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_a_1 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        M = cv2.moments(blob_det_b[1][0])\n",
    "        cX_b_0 = int(M[\"m01\"] / M[\"m00\"])\n",
    "        cY_b_0 = int(M[\"m10\"] / M[\"m00\"])\n",
    "        dist_1 = Vector2.magnitude(Vector2(cX_a_0 - cX_b_0, cY_a_0 - cY_b_0))\n",
    "        dist_2 = Vector2.magnitude(Vector2(cX_a_1 - cX_b_0, cY_a_1 - cY_b_0))\n",
    "        if(dist_1 <= dist_2):\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_b[1][0], blob_det_a[2][0], blob_det_b[2][0]))\n",
    "            blob_tuples.append((blob_det_a[1][1], blob_det_a[1][1], blob_det_a[2][1], blob_det_a[2][1]))\n",
    "        else:\n",
    "            blob_tuples.append((blob_det_a[1][1], blob_det_b[1][0], blob_det_a[2][1], blob_det_b[2][0]))\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_a[1][0], blob_det_a[2][0], blob_det_a[2][0]))\n",
    "    elif blob_det_a[0] == 0:\n",
    "        if blob_det_b[0] == 1:\n",
    "            blob_tuples.append((blob_det_b[1][0], blob_det_b[1][0], blob_det_b[2][0], blob_det_b[2][0]))\n",
    "        elif blob_det_b[0] == 2:\n",
    "            blob_tuples.append((blob_det_b[1][0], blob_det_b[1][0], blob_det_b[2][0], blob_det_b[2][0]))\n",
    "            blob_tuples.append((blob_det_b[1][1], blob_det_b[1][1], blob_det_b[2][1], blob_det_b[2][1]))\n",
    "    elif blob_det_b[0] == 0:\n",
    "        if blob_det_a[0] == 1:\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_a[1][0], blob_det_a[2][0], blob_det_a[2][0]))\n",
    "        elif blob_det_b[0] == 2:\n",
    "            blob_tuples.append((blob_det_a[1][0], blob_det_a[1][0], blob_det_a[2][0], blob_det_a[2][0]))\n",
    "            blob_tuples.append((blob_det_a[1][1], blob_det_a[1][1], blob_det_a[2][1], blob_det_a[2][1]))\n",
    "    else:\n",
    "        blob_tuples.append((blob_det_a[1][0], blob_det_b[1][0], blob_det_a[2][0], blob_det_b[2][0]))\n",
    "        \n",
    "    return blob_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first brings blobs to same shape through adding zeros\n",
    "# then interpolates linearly between the two blobs and the two centroids\n",
    "# finaly places the interpolated blob at the interpolated centroid position on a black image\n",
    "def interpolate_images(im_a, im_b, task_id, factor=0.5):\n",
    "    \n",
    "    new_img = np.zeros((27, 15))\n",
    "    blob_tuples = create_blob_tuples(im_a, im_b, task_id)\n",
    "    \n",
    "    for blob_a, blob_b, pos_a, pos_b in blob_tuples:\n",
    "        #pad blobs to same size with zeros\n",
    "        pad_a_0 = blob_b.shape[0] - blob_a.shape[0]\n",
    "        if pad_a_0 > 0:\n",
    "            blob_a = np.append(blob_a, np.zeros((pad_a_0, blob_a.shape[1])), axis=0)\n",
    "        pad_a_1 = blob_b.shape[1] - blob_a.shape[1]\n",
    "        if pad_a_1 > 0:\n",
    "            blob_a = np.append(blob_a, np.zeros((blob_a.shape[0], pad_a_1)), axis=1)\n",
    "        pad_b_0 = blob_a.shape[0] - blob_b.shape[0]\n",
    "        if pad_b_0 > 0:\n",
    "            blob_b = np.append(blob_b, np.zeros((pad_b_0, blob_b.shape[1])), axis=0)\n",
    "        pad_b_1 = blob_a.shape[1] - blob_b.shape[1]\n",
    "        if pad_b_1 > 0:\n",
    "            blob_b = np.append(blob_b, np.zeros((blob_b.shape[0], pad_b_1)), axis=1)\n",
    "        im_lerp = lerp(blob_a, blob_b, factor)\n",
    "        M = cv2.moments(im_lerp)\n",
    "        cY = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cX = int(M[\"m01\"] / M[\"m00\"])\n",
    "        #print(\"a: %s\" % str(blob_a.shape))\n",
    "        #print(\"b: %s\" % str(blob_b.shape))\n",
    "        blob_pos_x = int(lerp(pos_a[0], pos_b[0], factor))\n",
    "        blob_pos_y = int(lerp(pos_a[1], pos_b[1], factor))\n",
    "        pos_x_0 = blob_pos_x - cX\n",
    "        pos_x_1 = blob_pos_x - cX + im_lerp.shape[0]\n",
    "        pos_y_0 = blob_pos_y - cY\n",
    "        pos_y_1 = blob_pos_y - cY + im_lerp.shape[1]\n",
    "        if pos_x_0 < 0:\n",
    "            pos_x_1 += abs(pos_x_0)\n",
    "            pos_x_0 = 0\n",
    "        if pos_x_1 >= 27:\n",
    "            pos_x_0 += 26 - pos_x_1\n",
    "            pos_x_1 = 26\n",
    "        if pos_y_0 < 0:\n",
    "            pos_y_1 += abs(pos_y_0)\n",
    "            pos_y_0 = 0\n",
    "        if pos_y_1 >= 15:\n",
    "            pos_y_0 += 14 - pos_y_1\n",
    "            pos_y_1 = 14\n",
    "                    \n",
    "        new_img[pos_x_0:pos_x_1, pos_y_0:pos_y_1] = im_lerp\n",
    "    return new_img\n",
    "\n",
    "# only for testing\n",
    "for i in range(0, df_lstm.iloc[58].Blobs.shape[0] - 1):\n",
    "    im_a = df_lstm.iloc[58].Blobs[i]\n",
    "    im_b = df_lstm.iloc[58].Blobs[i + 1]\n",
    "    im_c = interpolate_images(im_a, im_b, 3)\n",
    "    #print(type(im_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines the positions, where to interpolate between images\n",
    "def stretch_images(cur_images, task_id, target_length=50):\n",
    "    new_images = []\n",
    "    factor = (cur_images.shape[0] - 1) / (target_length - 1)\n",
    "    \n",
    "    for i in range(0, target_length):\n",
    "        lower = int(i * factor)\n",
    "        higher = lower if lower == i * factor else lower + 1\n",
    "        if higher >= cur_images.shape[0]:\n",
    "            higher = cur_images.shape[0] - 1\n",
    "        local_factor = (i * factor) - int(i * factor)\n",
    "        #print(\"%s: val: %s, lower: %s, higher: %s, local: %s\" % (i, i * factor, lower, higher, local_factor))\n",
    "        new_img = interpolate_images(cur_images[lower], cur_images[higher], local_factor)\n",
    "        new_images.append(new_img)\n",
    "    return np.array(new_images)\n",
    "        \n",
    "#print(df_lstm.iloc[0].shape)\n",
    "#res = stretch_images(df_lstm.iloc[0].Blobs, df_lstm.iloc[0].TaskID, 30)\n",
    "#res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descides whether or not a normalization is neccessary\n",
    "def normalize_blobs(blobs, task_id, new_len=50):\n",
    "    new_count = new_len - blobs.shape[0]\n",
    "    if new_count == 0:\n",
    "        return blobs\n",
    "    else:\n",
    "        return stretch_images(blobs, task_id, new_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# normalizes all image sequences\n",
    "df_lstm_norm = df_lstm.copy(deep=True)\n",
    "new_blobs = []\n",
    "for index, row in df_lstm.iterrows():\n",
    "    new_blobs.append(normalize_blobs(row.Blobs, row.TaskID, 50))\n",
    "\n",
    "df_lstm_norm.Blobs = new_blobs\n",
    "\n",
    "lengths = []\n",
    "for index, row in df_lstm_norm.iterrows():\n",
    "    lengths.append(row.Blobs.shape[0])\n",
    "df_lstm_norm[\"BlobCount\"] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_norm.BlobCount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_norm.to_pickle(\"PklData/df_lstm_norm50_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
